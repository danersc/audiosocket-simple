Estrutura do projeto:
README.md
ai/
    __init__.py
    agents.py
    crew.py
    main.py
    models/
        __init__.py
        intent.py
    state_manager.py
    tasks.py
    tools.py
    utils/
        __init__.py
        intent_extractor.py
ai_service.py
audio_utils.py
audiosocket_handler.py
code_gpt.py
config.json
main.py
microfone_client.py
requirements.txt
speech_service.py
state_machine.py

C√≥digo fonte:

ai_service.py:
import logging
from ai.main import process_message  # Importa√ß√£o direta do CrewAI
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

async def enviar_mensagem_para_ia(texto: str, conversation_id: str) -> Dict[str, Any]:
    """
    Agora chama diretamente o CrewAI ao inv√©s da API externa.
    """
    try:
        logger.info("=" * 50)
        logger.info(f"Chamando CrewAI diretamente com mensagem: {texto}")
        resposta = process_message(content=texto, id=conversation_id)

        logger.info("=" * 50)
        logger.info(f"Resposta recebida do CrewAI:")
        logger.info(resposta)
        logger.info("=" * 50)

        # Adiciona o timestamp que antes era retornado pela API
        resposta_com_timestamp = {
            "content": resposta,
            "timestamp": ""
        }

        return resposta_com_timestamp

    except Exception as e:
        logger.error(f"Erro ao comunicar com CrewAI diretamente: {e}")
        return {
            "content": {
                "mensagem": "Desculpe, n√£o consegui processar sua solicita√ß√£o no momento.",
                "dados": {},
                "valid_for_action": False,
                "set_call_status": "USER_TURN"
            },
            "timestamp": ""
        }

def extrair_mensagem_da_resposta(resposta: Dict[str, Any]) -> str:
    return resposta.get("content", {}).get("mensagem", "")

def obter_estado_chamada(resposta: Dict[str, Any]) -> Optional[str]:
    return resposta.get("content", {}).get("set_call_status")


audiosocket_handler.py:
import asyncio
import logging
import webrtcvad
import struct
from speech_service import transcrever_audio_async, sintetizar_fala_async
from ai_service import enviar_mensagem_para_ia, extrair_mensagem_da_resposta, obter_estado_chamada
from state_machine import State
import os

KIND_SLIN = 0x10
logger = logging.getLogger(__name__)

async def receber_audio(reader, state_machine, audio_queue):
    try:
        while True:
            header = await reader.readexactly(3)
            kind = header[0]
            length = int.from_bytes(header[1:3], 'big')
            audio_chunk = await reader.readexactly(length)
            if kind == KIND_SLIN and len(audio_chunk) == 320 and state_machine.is_user_turn():
                await audio_queue.put(audio_chunk)
    except asyncio.IncompleteReadError:
        logger.info("Cliente desconectado")
    except Exception as e:
        logger.error(f"Erro ao receber √°udio: {e}")

async def enviar_audio(writer, dados_audio, origem="desconhecida"):
    logger.info(f"Iniciando envio de √°udio sintetizado (origem: {origem}), tamanho total: {len(dados_audio)} bytes")
    chunk_size = 320
    for i in range(0, len(dados_audio), chunk_size):
        chunk = dados_audio[i:i + chunk_size]
        if chunk:
            writer.write(struct.pack('>B H', KIND_SLIN, len(chunk)) + chunk)
            await writer.drain()
            await asyncio.sleep(0.02)
    logger.info(f"Envio de √°udio conclu√≠do (origem: {origem})")

async def enviar_audio_em_loop(writer, caminho_audio):
    with open(caminho_audio, 'rb') as f:
        dados_audio = f.read()

    chunk_size = 320
    try:
        while True:
            for i in range(0, len(dados_audio), chunk_size):
                chunk = dados_audio[i:i + chunk_size]
                if chunk:
                    writer.write(struct.pack('>B H', KIND_SLIN, len(chunk)) + chunk)
                    await writer.drain()
                    await asyncio.sleep(0.02)
    except asyncio.CancelledError:
        logger.info("√Åudio de espera cancelado.")

async def monitorar_waiting(state_machine, writer, caminho_audio):
    waiting_task = None
    while True:
        await state_machine.wait_for_state(State.WAITING)
        logger.info("Estado WAITING detectado, aguardando 3 segundos antes de iniciar √°udio de espera.")
        try:
            await asyncio.wait_for(state_machine.wait_for_state_change(), timeout=3.0)
            logger.info("Estado WAITING terminou antes dos 3 segundos, √°udio de espera n√£o ser√° iniciado.")
        except asyncio.TimeoutError:
            if state_machine.is_waiting():
                logger.info("Timeout atingido em WAITING, iniciando √°udio de espera.")
                waiting_task = asyncio.create_task(enviar_audio_em_loop(writer, caminho_audio))

                await state_machine.wait_for_state_change()
                if waiting_task:
                    waiting_task.cancel()
                    waiting_task = None

async def processar_audio(audio_queue, vad, state_machine, writer):
    frames = []
    is_speaking = False
    silence_start = None

    while True:
        chunk = await audio_queue.get()
        is_voice = vad.is_speech(chunk, 8000)

        if is_voice:
            frames.append(chunk)
            is_speaking = True
            silence_start = None
        elif is_speaking:
            if silence_start is None:
                silence_start = asyncio.get_event_loop().time()
            elif asyncio.get_event_loop().time() - silence_start > 2.0:
                is_speaking = False
                audio_data = b''.join(frames)
                frames.clear()

                if audio_data:
                    state_machine.transition_to(State.WAITING)
                    logger.info("√Åudio capturado completo, iniciando transcri√ß√£o.")

                    texto = await transcrever_audio_async(audio_data)

                    if not texto:
                        logger.warning("Nenhuma transcri√ß√£o obtida.")
                        state_machine.transition_to(State.USER_TURN)
                        continue

                    logger.info(f"Texto transcrito: {texto}")

                    resposta = await enviar_mensagem_para_ia(texto, state_machine.get_conversation_id())
                    mensagem = extrair_mensagem_da_resposta(resposta)
                    proximo_estado = obter_estado_chamada(resposta)

                    logger.info(f"Mensagem recebida da IA: {mensagem}")
                    logger.info(f"Estado sugerido pela API: {proximo_estado}")

                    if mensagem:
                        audio_resposta = await sintetizar_fala_async(mensagem)
                        if audio_resposta and len(audio_resposta) > 0:
                            state_machine.transition_to(State.IA_TURN)
                            logger.info("Enviando √°udio sintetizado ao usu√°rio.")
                            await enviar_audio(writer, audio_resposta, origem="IA Response")
                            await asyncio.sleep(0.5)
                        else:
                            logger.warning("Resposta de √°udio vazia.")

                    if proximo_estado:
                        logger.info(f"Aplicando estado '{proximo_estado}' ap√≥s envio completo do √°udio.")
                        state_machine.transition_to(State[proximo_estado])
                    else:
                        state_machine.transition_to(State.USER_TURN)

async def iniciar_servidor_audiosocket(reader, writer, state_machine):
    vad = webrtcvad.Vad(2)
    audio_queue = asyncio.Queue()
    caminho_audio_espera = os.path.join('audio', 'waiting.slin')

    logger.info("Iniciando s√≠ntese de √°udio para mensagem de sauda√ß√£o.")
    greeting_audio = await sintetizar_fala_async("Condom√≠nio Apoena, em que posso ajudar?")
    if greeting_audio:
        state_machine.transition_to(State.IA_TURN)
        logger.info("Enviando √°udio da mensagem inicial ao cliente.")
        await enviar_audio(writer, greeting_audio, origem="Greeting")
        await asyncio.sleep(0.5)

    # ‚úÖ Altera√ß√£o chave aqui: a transi√ß√£o para USER_TURN ocorre APENAS ap√≥s envio completo do √°udio
    state_machine.transition_to(State.USER_TURN)

    await asyncio.gather(
        receber_audio(reader, state_machine, audio_queue),
        processar_audio(audio_queue, vad, state_machine, writer),
        monitorar_waiting(state_machine, writer, caminho_audio_espera)
    )


requirements.txt:
azure-cognitiveservices-speech==1.41.1
httpx==0.27.2
pydub==0.25.1
python-dotenv==1.0.1
webrtcvad==2.0.10
asyncio
typing_extensions
fastapi
uvicorn[standard]
jinja2
pydantic
crewai==0.108.0
crewai-tools==0.38.1
redis==5.2.1
guardrails-ai==0.6.5


config.json:
{
    "greeting": {
        "message": "Condom√≠nio Apoena, em que posso ajudar?",
        "voice": "pt-BR-AntonioNeural",
        "delay_seconds": 2
    },
    "system": {
        "default_state": "STANDBY",
        "silence_threshold_seconds": 2.0,
        "max_transaction_time_seconds": 30
    },
    "audio": {
        "sample_rate": 8000,
        "channels": 1,
        "format": "SLIN",
        "chunk_size": 320
    }
}

state_machine.py:
#!/usr/bin/env python3
# state_machine.py - M√°quina de estado simplificada para gerenciar turnos de conversa

import enum
import logging
import uuid
from datetime import datetime
from typing import Callable, List, Dict, Optional
import asyncio  # <-- necess√°rio para as fun√ß√µes ass√≠ncronas adicionadas

logger = logging.getLogger(__name__)


class State(enum.Enum):
    """Estados simplificados para a conversa entre usu√°rio e IA."""
    STANDBY = "STANDBY"  # Estado inicial, aguardando nova chamada
    USER_TURN = "USER_TURN"  # Turno do usu√°rio (sistema est√° ouvindo)
    WAITING = "WAITING"  # Estado intermedi√°rio de processamento
    IA_TURN = "IA_TURN"  # Turno da IA (sistema est√° respondendo)


class StateMachine:
    """
    M√°quina de estados simplificada para controlar o fluxo de comunica√ß√£o
    entre o usu√°rio e a IA em uma chamada.
    """

    def __init__(self):
        self.current_state = State.STANDBY
        self.conversation_id = None
        self.state_change_callbacks: Dict[State, List[Callable]] = {
            state: [] for state in State
        }
        self.transcricoes = []
        self.ultima_resposta = None
        logger.info(f"M√°quina de estados inicializada em {self.current_state}")

    def get_state(self) -> State:
        return self.current_state

    def transition_to(self, new_state: State) -> None:
        if new_state == self.current_state:
            logger.debug(f"Ignorando transi√ß√£o redundante para {new_state}")
            return

        old_state = self.current_state
        self.current_state = new_state
        logger.info(f"Transi√ß√£o de estado: {old_state} -> {new_state}")

        if old_state == State.IA_TURN and new_state == State.USER_TURN:
            logger.info("*** IMPORTANTE: Transi√ß√£o de IA_TURN para USER_TURN - ativando escuta ***")
            self.registrar_transcricao_sistema("Sistema ativou escuta - aguardando fala do usu√°rio")
        elif old_state == State.WAITING:
            logger.info(f"Saindo do estado WAITING para {new_state}")
            self.registrar_transcricao_sistema(f"Estado alterado: {old_state.value} -> {new_state.value}")
        if new_state == State.USER_TURN:
            logger.info("*** Sistema pronto para ouvir o usu√°rio ***")

        for callback in self.state_change_callbacks.get(new_state, []):
            try:
                callback()
            except Exception as e:
                logger.error(f"Erro no callback de mudan√ßa de estado: {e}")

    def on_state_change(self, state: State, callback: Callable) -> None:
        if state in self.state_change_callbacks:
            self.state_change_callbacks[state].append(callback)

    def is_user_turn(self) -> bool:
        return self.current_state == State.USER_TURN

    def is_ai_turn(self) -> bool:
        return self.current_state == State.IA_TURN

    def is_waiting(self) -> bool:
        return self.current_state == State.WAITING

    def is_standby(self) -> bool:
        return self.current_state == State.STANDBY

    def start_new_conversation(self, standby=False) -> str:
        self.conversation_id = str(uuid.uuid4())
        self.transcricoes = []
        self.ultima_resposta = None

        if not standby:
            self.transition_to(State.USER_TURN)
        else:
            self.transition_to(State.STANDBY)

        logger.info(f"Nova conversa iniciada com ID: {self.conversation_id}")
        return self.conversation_id

    def registrar_transcricao_usuario(self, texto: str) -> None:
        self.transcricoes.append({
            "timestamp": datetime.now().isoformat(),
            "origem": "usuario",
            "texto": texto
        })
        logger.info(f"Transcri√ß√£o do usu√°rio registrada: {texto}")

    def registrar_transcricao_ia(self, texto: str, resposta_completa: Optional[Dict] = None) -> None:
        self.transcricoes.append({
            "timestamp": datetime.now().isoformat(),
            "origem": "ia",
            "texto": texto
        })
        self.ultima_resposta = resposta_completa
        logger.info(f"Resposta da IA registrada: {texto}")

    def registrar_transcricao_sistema(self, texto: str) -> None:
        self.transcricoes.append({
            "timestamp": datetime.now().isoformat(),
            "origem": "sistema",
            "texto": texto
        })
        logger.info(f"Mensagem do sistema registrada: {texto}")

    def obter_historico_transcricoes(self) -> List[Dict]:
        return self.transcricoes

    def get_conversation_id(self) -> Optional[str]:
        return self.conversation_id

    def end_conversation(self) -> None:
        logger.info(f"Conversa {self.conversation_id} finalizada")
        self.conversation_id = None
        self.transition_to(State.STANDBY)

    # Novas fun√ß√µes adicionadas:
    async def wait_for_state(self, state: State):
        """Aguarda at√© que o estado especificado seja atingido."""
        while self.current_state != state:
            await asyncio.sleep(0.1)

    async def wait_for_state_change(self):
        """Aguarda at√© que ocorra uma mudan√ßa do estado atual."""
        current_state = self.current_state
        while self.current_state == current_state:
            await asyncio.sleep(0.1)


README.md:
# AudioSocket Simple

Aplica√ß√£o simplificada para atendimento por IA em condom√≠nios utilizando o protocolo AudioSocket do Asterisk.

## Descri√ß√£o

Esta aplica√ß√£o √© respons√°vel por gerenciar chamadas VoIP atrav√©s do protocolo AudioSocket, realizando:

1. Detec√ß√£o de voz usando VAD (Voice Activity Detection)
2. Transcri√ß√£o do √°udio usando Azure Speech Services
3. Processamento de inten√ß√µes via API de IA
4. S√≠ntese de voz para respostas
5. Gerenciamento de turnos de conversa entre usu√°rio e IA

## Funcionalidades principais

- Socket TCP para comunica√ß√£o com o Asterisk via protocolo AudioSocket
- M√°quina de estados simplificada com 4 estados (STANDBY, USER_TURN, WAITING, IA_TURN)
- Gerenciamento de IDs de conversa para manter o contexto entre mensagens
- Mensagem de sauda√ß√£o autom√°tica configur√°vel
- Detec√ß√£o de voz e sil√™ncio usando webrtcvad
- Transcri√ß√£o de √°udio atrav√©s do Azure Speech Services
- Comunica√ß√£o com API de IA para processar mensagens do usu√°rio
- S√≠ntese de voz usando Azure Speech Services
- Interface web simples para debug e monitoramento

## Requisitos

- Python 3.8+
- Biblioteca webrtcvad para detec√ß√£o de voz
- Azure Speech Services para transcri√ß√£o e s√≠ntese de voz
- API de IA para processamento de mensagens

## Configura√ß√£o

1. Crie um arquivo `.env` com as seguintes vari√°veis de ambiente:
   ```
   AZURE_SPEECH_KEY=sua_chave_do_azure
   AZURE_SPEECH_REGION=sua_regiao_do_azure
   SILENCE_THRESHOLD_SECONDS=2.0
   AI_API_URL=http://localhost:8000/messages
   ```

2. Instale as depend√™ncias:
   ```
   pip install -r requirements.txt
   ```

3. Personalize a mensagem de sauda√ß√£o no arquivo `config.json`:
   ```json
   {
     "greeting": {
       "message": "Condom√≠nio Apoena, em que posso ajudar?",
       "voice": "pt-BR-AntonioNeural",
       "delay_seconds": 2
     },
     ...
   }
   ```

## Execu√ß√£o

### Servidor principal
Inicie o servidor principal que lida com a chamada e inclui a interface web de debug:
```
python main.py
```

O servidor AudioSocket ir√° escutar em 127.0.0.1:8080 e a interface web de debug estar√° dispon√≠vel em http://127.0.0.1:8081.

### Cliente de teste com microfone
Para testar o sistema com seu microfone local:
```
python microfone_client.py
```

Este cliente captura √°udio do microfone do seu computador e o envia para o servidor AudioSocket, permitindo testar toda a funcionalidade sem precisar do Asterisk.

Op√ß√µes dispon√≠veis:
```
python microfone_client.py --host 127.0.0.1 --port 8080
```

## Fluxo de conversa√ß√£o

1. **Estado STANDBY**: 
   - Sistema aguarda uma conex√£o
   - Ao receber uma conex√£o, registra o ID da chamada
   - Ap√≥s um breve delay, envia a mensagem de sauda√ß√£o
   
2. **Estado USER_TURN**:
   - Sistema ativa ap√≥s a sauda√ß√£o
   - Detecta quando o usu√°rio come√ßa a falar
   - Captura o √°udio at√© identificar sil√™ncio
   - Transcreve o √°udio usando Azure Speech
   
3. **Estado WAITING**:
   - Processa o texto transcrito
   - Envia para a API de IA
   
4. **Estado IA_TURN**:
   - Recebe a resposta da IA
   - Sintetiza a fala usando Azure Speech
   - Envia o √°udio de resposta
   - Retorna para USER_TURN ou STANDBY dependendo da resposta da IA

## Interface de Debug

A interface web de debug mostra:
- Estado atual da chamada
- ID da conversa ativa
- Hist√≥rico de transcri√ß√µes (usu√°rio, IA e sistema)

A p√°gina atualiza automaticamente a cada 2 segundos para mostrar o estado atual.

## API de IA

A aplica√ß√£o se comunica com uma API de IA pela URL `http://localhost:8000/messages` que deve retornar uma resposta no formato:

```json
{
    "content": {
        "mensagem": "Texto da resposta da IA",
        "dados": {
            "intent_type": "tipo_intencao",
            "outros_dados": "valores_relevantes"
        },
        "valid_for_action": false
    },
    "timestamp": "2025-04-15T19:17:59.052067",
    "set_call_status": "USER_TURN"
}
```

O campo `set_call_status` pode ter os valores: "USER_TURN", "WAITING", "IA_TURN" ou "STANDBY" para controlar o fluxo da conversa.

audio_utils.py:
#!/usr/bin/env python3
# audio_utils.py - Utilit√°rios para manipula√ß√£o de √°udio

from pydub import AudioSegment
from io import BytesIO
import logging

logger = logging.getLogger(__name__)

def converter_bytes_para_wav(dados_slin, sample_rate=8000):
    """
    Converte bytes no formato SLIN para WAV.
    
    Args:
        dados_slin: Bytes de √°udio no formato SLIN
        sample_rate: Taxa de amostragem (padr√£o: 8000 Hz)
        
    Returns:
        Bytes WAV do √°udio convertido
    """
    try:
        audio_segment = AudioSegment(
            data=bytes(dados_slin),
            sample_width=2,  # 16 bits = 2 bytes
            frame_rate=sample_rate,
            channels=1
        )
        buffer = BytesIO()
        audio_segment.export(buffer, format='wav')
        return buffer.getvalue()
    except Exception as e:
        logger.error(f"Erro ao converter bytes para WAV: {e}")
        return None

def converter_wav_para_slin(dados_wav, sample_rate=8000):
    """
    Converte bytes WAV para o formato SLIN.
    
    Args:
        dados_wav: Bytes de √°udio no formato WAV
        sample_rate: Taxa de amostragem desejada (padr√£o: 8000 Hz)
        
    Returns:
        Bytes SLIN do √°udio convertido
    """
    try:
        audio_segment = AudioSegment.from_file(BytesIO(dados_wav), format="wav")
        audio_segment = audio_segment.set_frame_rate(sample_rate).set_channels(1).set_sample_width(2)
        return audio_segment.raw_data
    except Exception as e:
        logger.error(f"Erro ao converter WAV para SLIN: {e}")
        return None

microfone_client.py:
#!/usr/bin/env python3
import socket, struct, threading, pyaudio, logging, uuid

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')

KIND_ID, KIND_SLIN, KIND_HANGUP = 0x01, 0x10, 0x00

class AudioSocketClient:
    def __init__(self, host='127.0.0.1', port=8080):
        self.host, self.port = host, port
        self.call_id = uuid.uuid4().bytes
        self.sample_rate, self.channels, self.chunk_size = 8000, 1, 320
        self.format = pyaudio.paInt16
        self.running = False

    def connect(self):
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket.connect((self.host, self.port))
        self.socket.sendall(struct.pack('>B H', KIND_ID, len(self.call_id)) + self.call_id)
        logging.info("Conectado ao servidor.")
        self.running = True
        threading.Thread(target=self.send_audio).start()
        threading.Thread(target=self.receive_audio).start()

    def send_audio(self):
        p = pyaudio.PyAudio()
        stream = p.open(format=self.format, channels=self.channels, rate=self.sample_rate, input=True, frames_per_buffer=self.chunk_size//2)
        try:
            while self.running:
                data = stream.read(self.chunk_size//2, exception_on_overflow=False)
                self.socket.sendall(struct.pack('>B H', KIND_SLIN, len(data)) + data)
        except Exception as e:
            logging.error(f"Erro no envio de √°udio: {e}")
            self.running = False
        stream.stop_stream()
        stream.close()
        p.terminate()

    def receive_audio(self):
        p = pyaudio.PyAudio()
        stream = p.open(format=self.format, channels=self.channels, rate=self.sample_rate, output=True)
        try:
            while self.running:
                header = self.socket.recv(3)
                if not header: break
                kind, length = header[0], struct.unpack('>H', header[1:3])[0]
                payload = self.socket.recv(length)
                if kind == KIND_SLIN:
                    stream.write(payload)
        except Exception as e:
            logging.error(f"Erro no recebimento de √°udio: {e}")
            self.running = False
        stream.stop_stream()
        stream.close()
        p.terminate()

    def disconnect(self):
        self.running = False
        self.socket.sendall(struct.pack('>B H', KIND_HANGUP, 0))
        self.socket.close()
        logging.info("Desconectado do servidor.")

if __name__ == "__main__":
    client = AudioSocketClient()
    try:
        client.connect()
        while client.running: pass
    except KeyboardInterrupt:
        client.disconnect()


code_gpt.py:
import os

IGNORE = {'__pycache__', '.env', '.git', '.idea', 'audio'}

def list_structure(base_path, prefix=""):
    tree = ""
    items = sorted(os.listdir(base_path))
    for item in items:
        if item in IGNORE:
            continue
        path = os.path.join(base_path, item)
        if os.path.isdir(path):
            tree += f"{prefix}{item}/\n"
            tree += list_structure(path, prefix + "    ")
        else:
            tree += f"{prefix}{item}\n"
    return tree

def list_code_files(base_path):
    code = ""
    for root, dirs, files in os.walk(base_path):
        dirs[:] = [d for d in dirs if d not in IGNORE]
        for file in files:
            if file in IGNORE:
                continue
            file_path = os.path.join(root, file)
            rel_path = os.path.relpath(file_path, base_path)
            code += f"\n{rel_path}:\n"
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    code += f.read() + "\n"
            except Exception as e:
                code += f"Erro ao ler arquivo: {e}\n"
    return code

def main():
    base_path = "."
    structure = list_structure(base_path)
    code_files = list_code_files(base_path)

    with open("code.txt", "w", encoding="utf-8") as f:
        f.write("Estrutura do projeto:\n")
        f.write(structure)
        f.write("\nC√≥digo fonte:\n")
        f.write(code_files)

    print("Arquivo 'code.txt' criado com sucesso.")

if __name__ == "__main__":
    main()


main.py:
import asyncio
import logging
from dotenv import load_dotenv
from state_machine import StateMachine
from audiosocket_handler import iniciar_servidor_audiosocket

load_dotenv()
logging.basicConfig(level=logging.INFO)

async def handle_client(reader, writer):
    state_machine = StateMachine()
    state_machine.start_new_conversation()

    # Lendo a mensagem inicial KIND_ID (esperado pelo cliente)
    try:
        header = await reader.readexactly(3)
        kind = header[0]
        length = int.from_bytes(header[1:3], "big")
        call_id = await reader.readexactly(length)

        if kind != 0x01:  # KIND_ID
            logging.error("Mensagem inicial n√£o √© KIND_ID. Fechando conex√£o.")
            writer.close()
            await writer.wait_closed()
            return

        logging.info(f"Recebido Call ID: {call_id.hex()}")

        # Agora iniciar o servidor audio socket normalmente
        await iniciar_servidor_audiosocket(reader, writer, state_machine)

    except asyncio.IncompleteReadError:
        logging.error("Cliente desconectado inesperadamente.")
    except Exception as e:
        logging.error(f"Erro inesperado: {e}")
    finally:
        writer.close()
        await writer.wait_closed()

async def main():
    server = await asyncio.start_server(handle_client, '127.0.0.1', 8080)
    logging.info("Servidor AudioSocket rodando em 127.0.0.1:8080")
    async with server:
        try:
            await server.serve_forever()
        except asyncio.CancelledError:
            logging.info("Servidor est√° sendo encerrado.")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("Servidor encerrado manualmente.")


speech_service.py:
import asyncio
from io import BytesIO

from audio_utils import converter_bytes_para_wav, converter_wav_para_slin
import azure.cognitiveservices.speech as speechsdk
import os
from pydub import AudioSegment

async def transcrever_audio_async(dados_audio_slin):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, transcrever_audio, dados_audio_slin)

async def sintetizar_fala_async(texto):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, sintetizar_fala, texto)

def transcrever_audio(dados_audio_slin):
    audio_wav = converter_bytes_para_wav(dados_audio_slin, 8000)
    if not audio_wav:
        return None
    audio_segment = AudioSegment.from_file(BytesIO(audio_wav), format="wav")
    audio_segment = audio_segment.set_frame_rate(16000)
    buffer = BytesIO()
    audio_segment.export(buffer, format='wav')
    audio_wav_16k = buffer.getvalue()
    speech_config = speechsdk.SpeechConfig(subscription=os.getenv('AZURE_SPEECH_KEY'), region=os.getenv('AZURE_SPEECH_REGION'))
    speech_config.speech_recognition_language = 'pt-BR'
    audio_stream = speechsdk.audio.PushAudioInputStream()
    audio_stream.write(audio_wav_16k)
    audio_stream.close()
    audio_config = speechsdk.audio.AudioConfig(stream=audio_stream)
    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)
    result = recognizer.recognize_once()
    return result.text if result.reason == speechsdk.ResultReason.RecognizedSpeech else None

def sintetizar_fala(texto):
    speech_config = speechsdk.SpeechConfig(subscription=os.getenv('AZURE_SPEECH_KEY'), region=os.getenv('AZURE_SPEECH_REGION'))
    speech_config.speech_synthesis_language = 'pt-BR'
    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)
    result = synthesizer.speak_text_async(texto).get()
    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        return converter_wav_para_slin(result.audio_data, 8000)
    return None


ai/state_manager.py:
import redis
import json

r = redis.Redis(host='localhost', port=6379, decode_responses=True)

def get_user_state(id: str):
    data = r.get(id)
    return json.loads(data) if data else {"intent": {}, "history": []}

def update_user_state(user_id: str, intent=None, message=None):
    state = get_user_state(user_id)
    if intent:
        state["intent"].update(intent)
    if message:
        state["history"].append(message)
    r.set(user_id, json.dumps(state))

def clear_user_state(user_id: str):
    r.delete(user_id)


ai/tasks.py:
from crewai import Task
from ai.agents import create_conversation_coordinator_agent, create_conversation_monitor_agent


def create_conversation_coordinator_task(user_message: str, conversation_history: str, intent: dict) -> Task:
    agent = create_conversation_coordinator_agent()
    monitor = create_conversation_monitor_agent()
    print(conversation_history)
    return Task(
        description=f"""
        Voc√™ √© um concierge virtual em uma conversa com algu√©m no port√£o do condom√≠nio.

        Hist√≥rico da conversa:
        {conversation_history}

        Mensagem nova:
        "{user_message}"

        Inten√ß√£o acumulada at√© agora:
        {intent}

        Seu trabalho:
        - Verificar se todos os campos est√£o preenchidos:
          ‚Ä¢ intent_type
          ‚Ä¢ visitor_name
          ‚Ä¢ apartment_number
          ‚Ä¢ resident_name
        - Se faltar algo, pergunte o que falta.
        - Se estiver completo, apenas confirme.

        Regras:
        - N√ÉO repita o que j√° foi dito.
        - N√ÉO reinicie a conversa.
        - N√£o pe√ßa dados que j√° est√£o no intent.
        """,
        # expected_output="""
        # Mensagem para o usu√°rio ou confirma√ß√£o final.
        # Confirme a a√ß√£o de forma educada, objetiva e breve.
        # Exemplos de formato desejado:
        # - "Entrega confirmada para Fulano no xxxx. Notificarei o morador."
        # - "Entendido, vou avisar Cicrano no apartamento bla bla bla."
        # Evite repeti√ß√µes desnecess√°rias, n√£o deseje bom dia ou acrescente floreios.
        # """,
        expected_output=""""
        Responda em formato JSON com os seguintes campos:
        - mensagem: mensagem de resposta clara e objetiva para o usu√°rio, podendo ser a confirma√ß√£o final. 
        Confirme a a√ß√£o de forma educada, objetiva e breve. Ex, "Entrega confirmada para Fulano no xxxx. Notificarei o 
        morador"., ou ainda, "Entendido, vou avisar Cicrano no apartamento bla bla bla."
        - dados: objeto com os campos intent_type, visitor_name, apartment_number e resident_name.
        
        Exemplo:
        {
          "mensagem": "Entrega confirmada para Fulano do XXXX.",
          "dados": {
            "intent_type": "entrega",
            "visitor_name": "Jo√£o",
            "apartment_number": "XXXX",
            "resident_name": "Fulano"
          }
        }
        O campo message √© sempre obrigat√≥rio, pois voc√™ sempre deve ter uma resposta, mesmo que seja uma pergunta para 
        quem est√° sendo atendido. Se n√£o puder identificar os campos de dados, retorne as chaves com valores vazios. 
        N√£o use floreios, n√£o repita informa√ß√µes j√° ditas, apenas informe ou confirme a a√ß√£o.
        O campo intent_type dentro de dados deve ser preenchido com entrega, visita ou desconhecido, conforme o que 
        voc√™ identificar.
        
        Alguns exemplos de campos faltando e poss√≠veis respostas:
        {
          "mensagem": "Informe o que deseja",
          "dados": {
            "intent_type": "",
            "visitor_name": "",
            "apartment_number": "",
            "resident_name": ""
          }
        }
        
        {
          "mensagem": "Por favor, me informe o nome do visitante, o apartamento e o nome do morador que autorizou",
          "dados": {
            "intent_type": "visita",
            "visitor_name": "",
            "apartment_number": "",
            "resident_name": ""
          }
        } 
        
        {
          "mensagem": "Por favor, me informe o seu nome, o apartamento e o nome do morador que vai receber a entrega",
          "dados": {
            "intent_type": "entrega",
            "visitor_name": "",
            "apartment_number": "",
            "resident_name": ""
          }
        }                 
                
        {
          "mensagem": "Por favor, me informe o nome do morador.",
          "dados": {
            "intent_type": "entrega",
            "visitor_name": "Carlos",
            "apartment_number": "301",
            "resident_name": ""
          }
        }
        
        {
          "mensagem": "Por favor, me informe sua inten√ß√£o",
          "dados": {
            "intent_type": "",
            "visitor_name": "Carlos",
            "apartment_number": "301",
            "resident_name": "Fulano"
          }
        }
        
        {
          "mensagem": "Podes informar o seu nome?",
          "dados": {
            "intent_type": "visita",
            "visitor_name": "",
            "apartment_number": "301",
            "resident_name": "Fulano"
          }
        }      
        
        {
          "mensagem": "Podes informar o n√∫mero do apartamento?",
          "dados": {
            "intent_type": "visita",
            "visitor_name": "Cicrano",
            "apartment_number": "",
            "resident_name": "Fulano"
          }
        }              
        
        
        """,
        agent=agent
    )


ai/tools.py:
from crewai.tools import tool


@tool("SendMessageTool")
def identify_user_intent(message: str) -> str:
    """
    Extrai inten√ß√£o do usu√°rio com base na mensagem utilizando um modelo LLM.
    Retorna um JSON no formato esperado por UserIntent.
    """
    return message


ai/__init__.py:


ai/agents.py:
import os
from crewai import Agent

def create_conversation_coordinator_agent() -> Agent:
    """
    Cria e retorna um agente respons√°vel por conversar com o usu√°rio,
    entender sua inten√ß√£o e coletar todas as informa√ß√µes necess√°rias.
    """
    return Agent(
        role="Concierge Virtual do Condom√≠nio",
        goal="Atender o usu√°rio com empatia e efici√™ncia, entendendo e completando sua solicita√ß√£o",
        backstory="""
        Voc√™ √© um concierge virtual treinado que conversa com pessoas no interfone da portaria de um condom√≠nio.

        Seu trabalho √©:
        - Entender se a pessoa deseja fazer uma entrega ou visita (obrigat√≥rio)
        - Coletar todas as informa√ß√µes necess√°rias:
          ‚Ä¢ Quem est√° no port√£o (visitor_name) (obrigat√≥rio)
          ‚Ä¢ N√∫mero do apartamento de destino (apartment_number) (obrigat√≥rio)
          ‚Ä¢ Nome do morador (resident_name) (obrigat√≥rio)
        - Confirmar quando tudo estiver preenchido
        - Jamais perguntar algo que o usu√°rio j√° informou
        - Nunca delegar sua responsabilidade de entender a solicita√ß√£o
        - Nunca confunda entrega com visita, se o morador diz que vai ou deseja ir em um apartamento, prov√°vel visita

        Quando tiver todas as informa√ß√µes, apenas finalize a conversa com uma resposta simp√°tica e diga que ir√° notificar o morador.
        """,
        verbose=False,
        allow_delegation=False,
    )


def create_conversation_monitor_agent() -> Agent:
    """
    Cria e retorna um agente respons√°vel por conversar com o usu√°rio,
    entender sua inten√ß√£o e coletar todas as informa√ß√µes necess√°rias.
    """
    return Agent(
        role="Gerente do Concierge Virtual do Condom√≠nio",
        goal="Supervisionar o concierge virtual e garantir que ele vai extrair todos os dados que precisamos do usu√°rio",
        backstory="""
        Voc√™ √© um gerente senior e sua fun√ß√£o √© garantir que os etendentes da portaria remota (concierge virtual) 
        extraiam as informa√ß√µes corretas do usu√°rio. H√° relatos de que os atendentes est√£o chamando o morador, sem saber 
        qual a inten√ß√£o ou sequer perguntar o nome de quem est√° falando ou se deseja uma visita ou entrega. 

        Seu trabalho √©:
        - Identificar primeiro a pessoa que est√° falando com o concierge virtual e qual sua inten√ß√£o
        - Somente pergunte o nome do morador e o apartamento se j√° houver identificado a intera√ß√£o e o nome do vistnate ou entregador
        - Fiscalizar o trabalho do concierge virtual
        - Garantir que ele vau coletar todas as informa√ß√µes necess√°rias:
          ‚Ä¢ Identificar a inten√ß√£o do usu√°rio (intent_type) obrigat√≥rio: se √© visita ou entrega
          ‚Ä¢ Quem est√° no port√£o (visitor_name) (obrigat√≥rio)
          ‚Ä¢ N√∫mero do apartamento de destino (apartment_number) (obrigat√≥rio)
          ‚Ä¢ Nome do morador (resident_name) (obrigat√≥rio)
        - Nunca finalize a conversa se qualquer campo estiver vazio.
        - Se o nome do morador estiver vazio, voc√™ deve perguntar isso.

        Fiscalize as respostas antes de serem enviadas ao usu√°rio garantindo tudo que foi solicitado.
        """,
        verbose=False,
        allow_delegation=False,
    )


ai/crew.py:
from crewai import Crew

from ai.state_manager import get_user_state, update_user_state, clear_user_state
from ai.tasks import create_conversation_coordinator_task
from ai.utils.intent_extractor import extract_intent_from_response
from ai.models.intent import IntentData
import json

def process_user_message_with_coordinator(id: str, message: str) -> dict:
    state = get_user_state(id)
    history = "\n".join(state["history"])
    partial_intent = state["intent"]

    # Cria a Task com hist√≥rico e dados parciais
    task = create_conversation_coordinator_task(
        user_message=message,
        conversation_history=history,
        intent=partial_intent
    )

    crew = Crew(tasks=[task], verbose=True)
    result = str(crew.kickoff())

    # Tenta extrair novos dados (voc√™ pode usar OpenAI function calling ou Regex/JSON)
    try:
        dados_estruturados = extract_intent_from_response(result)
        update_user_state(id, intent=dados_estruturados.get("dados"), message=f"Usu√°rio: {message}\nResposta LLM: {dados_estruturados.get('mensagem')}")
    except Exception:
        update_user_state(id, message=f"Usu√°rio: {dados_estruturados.get('mensagem')}")

    return dados_estruturados


ai/main.py:
from ai.crew import process_user_message_with_coordinator



def process_message(content: str, id: str = "anon") -> dict:
    try:
        return process_user_message_with_coordinator(id=id, message=content)
            
    except Exception as e:
        print(f"Erro ao chamar CrewAI: {e}")
        return "Estou enfrentando alguns problemas t√©cnicos. Por favor, tente novamente mais tarde."


ai/utils/__init__.py:


ai/utils/intent_extractor.py:
import json

from guardrails import Guard
from typing import Dict

from humanfriendly.terminal import message

from ai.models.intent import IntentData, IntentType, FullIntentResponse

# =======================
# üõ°Ô∏è RAILS SCHEMA (sem valid_for_action)
# =======================

INTENT_SCHEMA = """
<rail version="0.1">
<output>
  <object>
    <string name="mensagem" description="Mensagem a ser enviada ao usu√°rio, clara e objetiva"/>
    <object name="dados">
      <string name="intent_type" format="enum" enum-values="visita,entrega,desconhecido"/>
      <string name="visitor_name" on-fail-soft="noop"/>
      <string name="apartment_number" on-fail-soft="noop"/>
      <string name="resident_name" on-fail-soft="noop"/>
    </object>
  </object>
</output>
</rail>
"""

guard = Guard.for_rail_string(INTENT_SCHEMA)

# =======================
# üîç EXTRACTOR
# =======================

def extract_intent_from_response(response: str) -> Dict:
    """
    Valida e extrai os dados de inten√ß√£o usando Guardrails e Pydantic.
    Calcula valid_for_action com base nos campos preenchidos.
    """
    try:
        validated  = guard.parse(response)
        raw = validated.validated_output

        if not all(k in raw for k in ["mensagem", "dados"]):
            raise ValueError("Resposta fora do padr√£o esperado")

        if raw["dados"].get("intent_type") == "":
            raw["dados"]["intent_type"] = IntentType.DESCONHECIDO

        intent = IntentData(**raw["dados"])

        # C√°lculo de completude
        campos_preenchidos = all([
            intent.intent_type != IntentType.DESCONHECIDO,
            intent.visitor_name.strip(),
            intent.apartment_number.strip(),
            intent.resident_name.strip()
        ])

        call_status = "USER_TURN"
        if campos_preenchidos:
            call_status = "WAITING"

        result = FullIntentResponse(
            mensagem=raw["mensagem"],
            dados=intent,
            valid_for_action=campos_preenchidos,
            set_call_status=call_status
        )

        return result.model_dump()
    except Exception as e:
        try:
            message_of_non_understanding = json.loads(message)
        except:
            message_of_non_understanding = {
                "mensagem": "N√£o foi poss√≠vel identificar sua inten√ß√£o e seu nome, por favor, me informe seu nome e o que deseja.",
                "dados": {
                    "intent_type": "",
                    "visitor_name": "",
                    "apartment_number": "",
                    "resident_name": "",
                    "set_call_status": "USER_TURN"
                }
            }
        message_of_non_understanding['dados']['intent_type'] = IntentType.DESCONHECIDO
        message_of_non_understanding['valid_for_action'] = False
        return message_of_non_understanding


ai/models/intent.py:
from enum import Enum
from typing import Optional

from pydantic import BaseModel, Field

# =======================
# üß† MODELO DE INTEN√á√ÉO
# =======================

class IntentType(str, Enum):
    VISITA = "visita"
    ENTREGA = "entrega"
    DESCONHECIDO = "desconhecido"

class IntentData(BaseModel):
    intent_type: IntentType = Field(..., description="Tipo de inten√ß√£o identificada")
    visitor_name: str = Field("", description="Nome da pessoa no port√£o")
    apartment_number: str = Field("", description="N√∫mero do apartamento de destino")
    resident_name: str = Field("", description="Nome do morador/destinat√°rio")

class FullIntentResponse(BaseModel):
    mensagem: str
    dados: IntentData
    valid_for_action: bool
    set_call_status: Optional[str] = "USER_TURN"


ai/models/__init__.py:

