Estrutura do projeto:
.gitignore
ai/
    __init__.py
    agents.py
    crew.py
    main.py
    models/
        __init__.py
        intent.py
    state_manager.py
    tasks.py
    tools.py
    utils/
        __init__.py
        intent_extractor.py
ai_service.py
audio_utils.py
audiosocket_handler.py
code_gpt.py
config.json
conversation_flow.py
data/
    apartamentos.json
docs/
    README.md
    resume.md
main.py
microfone_client.py
requirements.txt
services/
    __init__.py
    amqp_service.py
session_manager.py
speech_service.py
state_machine.py
test_logs.py
utils/
    README.md
    __init__.py
    call_logger.py
    log_analyzer.py

Código fonte:

ai_service.py:
import logging
from ai.main import process_message  # Importação direta do CrewAI
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

async def enviar_mensagem_para_ia(texto: str, conversation_id: str) -> Dict[str, Any]:
    """
    Agora chama diretamente o CrewAI ao invés da API externa.
    """
    try:
        logger.info("=" * 50)
        logger.info(f"Chamando CrewAI diretamente com mensagem: {texto}")
        resposta = process_message(content=texto, id=conversation_id)

        logger.info("=" * 50)
        logger.info(f"Resposta recebida do CrewAI:")
        logger.info(resposta)
        logger.info("=" * 50)

        # Adiciona o timestamp que antes era retornado pela API
        resposta_com_timestamp = {
            "content": resposta,
            "timestamp": ""
        }

        return resposta_com_timestamp

    except Exception as e:
        logger.error(f"Erro ao comunicar com CrewAI diretamente: {e}")
        return {
            "content": {
                "mensagem": "Desculpe, não consegui processar sua solicitação no momento.",
                "dados": {},
                "valid_for_action": False,
                "set_call_status": "USER_TURN"
            },
            "timestamp": ""
        }

def extrair_mensagem_da_resposta(resposta: Dict[str, Any]) -> str:
    return resposta.get("content", {}).get("mensagem", "")

def obter_estado_chamada(resposta: Dict[str, Any]) -> Optional[str]:
    return resposta.get("content", {}).get("set_call_status")


audiosocket_handler.py:
# audiosocket_handler.py

import asyncio
import logging
import struct
import os
import time

import webrtcvad

from speech_service import transcrever_audio_async, sintetizar_fala_async
from session_manager import SessionManager  # Importamos o SessionManager
from utils.call_logger import CallLoggerManager  # Importamos o CallLoggerManager

# Caso você use um "StateMachine" separado, pode remover ou adaptar:
# from state_machine import State

logger = logging.getLogger(__name__)

# Identificador do formato SLIN
KIND_SLIN = 0x10

# Podemos instanciar um SessionManager aqui como singleton/global.
# Se preferir criar em outro lugar, adapte.
session_manager = SessionManager()


async def enviar_audio(writer: asyncio.StreamWriter, dados_audio: bytes, call_id: str = None, origem="desconhecida"):
    """
    Envia dados de áudio (SLIN) ao cliente via 'writer'.
    """
    logger.info(f"[{origem}] Enviando áudio de {len(dados_audio)} bytes.")
    
    # Registrar no log específico da chamada
    if call_id:
        is_visitor = (origem == "Visitante")
        call_logger = CallLoggerManager.get_logger(call_id)
        call_logger.log_event("AUDIO_SEND_START", {
            "target": "visitor" if is_visitor else "resident",
            "audio_size_bytes": len(dados_audio)
        })
    
    start_time = time.time()
    chunk_size = 320
    for i in range(0, len(dados_audio), chunk_size):
        chunk = dados_audio[i : i + chunk_size]
        header = struct.pack(">B H", KIND_SLIN, len(chunk))
        writer.write(header + chunk)
        await writer.drain()
        # Pequeno atraso para não encher o buffer do lado do Asterisk
        await asyncio.sleep(0.02)
    
    # Registrar conclusão
    if call_id:
        duration_ms = (time.time() - start_time) * 1000
        call_logger.log_event("AUDIO_SEND_COMPLETE", {
            "target": "visitor" if is_visitor else "resident",
            "duration_ms": round(duration_ms, 2)
        })


async def receber_audio_visitante(reader: asyncio.StreamReader, call_id: str):
    """
    Tarefa que fica lendo o áudio do visitante, detecta quando ele fala (usando VAD)
    e chama `session_manager.process_visitor_text(...)` ao fim de cada frase.
    
    Agora com controle de estado para evitar retroalimentação durante a fala da IA.
    """
    call_logger = CallLoggerManager.get_logger(call_id)
    vad = webrtcvad.Vad(2)  # Agressivo 0-3
    frames = []
    is_speaking = False
    silence_start = None
    speech_start = None
    
    # Para controlar se estamos no modo de escuta ativa
    is_listening_mode = True
    
    # Acessar a sessão para verificar o estado
    session = session_manager.get_session(call_id)
    if not session:
        logger.error(f"[{call_id}] Sessão não encontrada para iniciar recebimento de áudio")
        return
    
    # Flag de buffer para descartar áudio residual após IA falar
    discard_buffer_frames = 0
    
    while True:
        try:
            header = await reader.readexactly(3)
        except asyncio.IncompleteReadError:
            logger.info(f"[{call_id}] Visitante desconectou (EOF).")
            call_logger.log_call_ended("visitor_disconnected")
            break

        if not header:
            logger.info(f"[{call_id}] Nenhum dado de header, encerrando.")
            call_logger.log_call_ended("invalid_header")
            break

        kind = header[0]
        length = int.from_bytes(header[1:3], "big")

        audio_chunk = await reader.readexactly(length)
        
        # Verificar o estado atual da sessão
        current_state = session.visitor_state
        
        # Se estamos em IA_TURN, significa que a IA está falando - não devemos processar VAD
        if current_state == "IA_TURN":
            is_listening_mode = False
            continue  # Pula processamento durante fala da IA
            
        # Período de transição: após IA falar, descartamos alguns frames para evitar eco
        if discard_buffer_frames > 0:
            discard_buffer_frames -= 1
            continue
            
        # Se acabamos de transitar de IA_TURN para USER_TURN, ativamos modo de escuta e descartamos frames iniciais
        if not is_listening_mode and current_state == "USER_TURN":
            is_listening_mode = True
            discard_buffer_frames = 25  # ~0.5s de áudio para descartar possível eco
            logger.debug(f"[{call_id}] Ativando modo de escuta de visitante")
            call_logger.log_event("LISTENING_MODE_ACTIVATED", {"timestamp": time.time()})
            
            # Limpar quaisquer frames acumulados anteriormente
            frames = []
            is_speaking = False
            silence_start = None
            speech_start = None
            continue

        # Processamos VAD apenas quando estamos em modo de escuta
        if is_listening_mode and kind == KIND_SLIN and len(audio_chunk) == 320:
            # Avalia VAD
            is_voice = vad.is_speech(audio_chunk, 8000)
            if is_voice:
                frames.append(audio_chunk)
                if not is_speaking:
                    is_speaking = True
                    speech_start = asyncio.get_event_loop().time()
                    logger.debug(f"[{call_id}] Visitante começou a falar.")
                    call_logger.log_speech_detected(is_visitor=True)
                silence_start = None
            else:
                if is_speaking:
                    # Já estava falando e agora está em silêncio
                    if silence_start is None:
                        silence_start = asyncio.get_event_loop().time()
                    else:
                        # Se passou 2s em silêncio, considera que a fala terminou
                        silence_duration = asyncio.get_event_loop().time() - silence_start
                        if silence_duration > 2.0:
                            is_speaking = False
                            
                            # Se não temos frames suficientes (< 1s), provavelmente é ruído
                            if len(frames) < 50:  # ~1 segundo de áudio (50 frames de 20ms)
                                logger.debug(f"[{call_id}] Descartando fala curta demais ({len(frames)} frames)")
                                frames = []
                                continue
                            
                            # Calcular duração total da fala
                            speech_duration = (asyncio.get_event_loop().time() - speech_start) * 1000
                            logger.debug(f"[{call_id}] Visitante parou de falar após {speech_duration:.0f}ms.")
                            call_logger.log_speech_ended(speech_duration, is_visitor=True)
                            call_logger.log_silence_detected(silence_duration * 1000, is_visitor=True)
                            
                            audio_data = b"".join(frames)
                            frames.clear()

                            # Desativar escuta durante processamento para evitar retroalimentação
                            is_listening_mode = False
                            
                            # Log antes da transcrição
                            call_logger.log_transcription_start(len(audio_data), is_visitor=True)
                            
                            # Mudar estado para WAITING durante processamento
                            session.visitor_state = "WAITING"
                            
                            # Transcrever com medição de tempo
                            start_time = time.time()
                            texto = await transcrever_audio_async(audio_data)
                            transcription_time = (time.time() - start_time) * 1000
                            
                            if texto:
                                call_logger.log_transcription_complete(texto, transcription_time, is_visitor=True)
                                
                                # Medição do tempo de processamento da IA
                                start_time = time.time()
                                session_manager.process_visitor_text(call_id, texto)
                                ai_processing_time = (time.time() - start_time) * 1000
                                
                                call_logger.log_event("VISITOR_PROCESSING_COMPLETE", {
                                    "text": texto,
                                    "processing_time_ms": round(ai_processing_time, 2)
                                })
                                
                                # Agora, mesmo que o estado tenha mudado para IA_TURN durante o processamento,
                                # vamos respeitar isso (is_listening_mode já está False)
                            else:
                                call_logger.log_error("TRANSCRIPTION_FAILED", 
                                                    "Falha ao transcrever áudio do visitante", 
                                                    {"audio_size": len(audio_data)})
                                # Voltar ao modo de escuta, já que não conseguimos processar o áudio
                                is_listening_mode = True
        elif kind != KIND_SLIN or len(audio_chunk) != 320:
            logger.warning(f"[{call_id}] Chunk inválido do visitante. kind={kind}, len={len(audio_chunk)}")
            call_logger.log_error("INVALID_CHUNK", 
                                "Chunk de áudio inválido recebido do visitante", 
                                {"kind": kind, "length": len(audio_chunk)})

    # Ao sair, encerrou a conexão
    logger.info(f"[{call_id}] receber_audio_visitante terminou.")


async def enviar_mensagens_visitante(writer: asyncio.StreamWriter, call_id: str):
    """
    Tarefa que periodicamente verifica se há mensagens pendentes
    para o visitante no SessionManager, sintetiza e envia via áudio.
    
    Atualiza o estado da sessão durante a fala da IA para evitar retroalimentação.
    """
    call_logger = CallLoggerManager.get_logger(call_id)
    
    # Verificar se a sessão existe
    session = session_manager.get_session(call_id)
    if not session:
        logger.error(f"[{call_id}] Sessão não encontrada para enviar mensagens")
        return
    
    while True:
        await asyncio.sleep(0.2)  # Ajuste conforme sua necessidade

        # Tenta buscar uma mensagem
        msg = session_manager.get_message_for_visitor(call_id)
        if msg is not None:
            logger.info(f"[{call_id}] Enviando mensagem ao visitante: {msg}")
            
            # IMPORTANTE: Mudar estado para IA_TURN antes de começar a falar
            # Isso sinaliza para o VAD parar de processar durante a fala
            old_state = session.visitor_state
            session.visitor_state = "IA_TURN"
            
            call_logger.log_event("STATE_CHANGE", {
                "from": old_state,
                "to": "IA_TURN",
                "reason": "ia_speaking"
            })
            
            call_logger.log_synthesis_start(msg, is_visitor=True)
            
            # Medir tempo de síntese
            start_time = time.time()
            audio_resposta = await sintetizar_fala_async(msg)
            synthesis_time = (time.time() - start_time) * 1000
            
            # Se falhou na síntese, voltamos ao estado anterior
            if not audio_resposta:
                call_logger.log_error("SYNTHESIS_FAILED", 
                                     "Falha ao sintetizar mensagem para o visitante", 
                                     {"message": msg})
                
                # Voltar ao estado anterior
                session.visitor_state = old_state
                call_logger.log_event("STATE_CHANGE", {
                    "from": "IA_TURN",
                    "to": old_state,
                    "reason": "synthesis_failed"
                })
                continue
                
            # Síntese bem-sucedida, enviar áudio
            call_logger.log_synthesis_complete(len(audio_resposta), synthesis_time, is_visitor=True)
            
            # Tempo estimado para reprodução (baseado no tamanho do áudio)
            # A taxa de amostragem é 8000Hz com 16 bits por amostra
            # Aproximadamente (len(audio_resposta) / 16000) segundos de áudio
            playback_duration_ms = (len(audio_resposta) / 16) * 1000
            call_logger.log_event("ESTIMATED_PLAYBACK_DURATION", {
                "duration_ms": playback_duration_ms,
                "audio_size_bytes": len(audio_resposta)
            })
            
            # Enviar o áudio (isso já registra logs de envio)
            await enviar_audio(writer, audio_resposta, call_id=call_id, origem="Visitante")
            
            # Adicionar um pequeno atraso após o envio do áudio para garantir
            # que o áudio seja totalmente reproduzido antes de voltar a escutar
            # Os 0.5s adicionais são para criar um buffer de segurança
            post_audio_delay = 0.5
            await asyncio.sleep(post_audio_delay)
            
            # Mudar de volta para USER_TURN para que o sistema possa escutar o usuário
            session.visitor_state = "USER_TURN"
            call_logger.log_event("STATE_CHANGE", {
                "from": "IA_TURN",
                "to": "USER_TURN",
                "reason": "ia_finished_speaking"
            })


async def iniciar_servidor_audiosocket_visitante(reader, writer):
    header = await reader.readexactly(3)
    kind = header[0]
    length = int.from_bytes(header[1:3], "big")
    call_id_bytes = await reader.readexactly(length)
    call_id = call_id_bytes.hex()

    logger.info(f"[VISITANTE] Recebido Call ID: {call_id}")
    
    # Inicializar logger específico para esta chamada
    call_logger = CallLoggerManager.get_logger(call_id)
    call_logger.log_event("CALL_SETUP", {
        "type": "visitor",
        "call_id": call_id
    })

    session_manager.create_session(call_id)

    # SAUDAÇÃO:
    welcome_msg = "Olá, seja bem-vindo! Em que posso ajudar?"
    call_logger.log_event("GREETING", {"message": welcome_msg})
    
    session_manager.enfileirar_visitor(
        call_id,
        welcome_msg
    )

    task1 = asyncio.create_task(receber_audio_visitante(reader, call_id))
    task2 = asyncio.create_task(enviar_mensagens_visitante(writer, call_id))

    # Espera até que alguma das tarefas termine (em geral, quando visitante desconecta).
    start_time = time.time()
    done, pending = await asyncio.wait([task1, task2], return_when=asyncio.FIRST_COMPLETED)
    call_duration = (time.time() - start_time) * 1000
    
    logger.info(f"[{call_id}] Alguma tarefa finalizou, vamos encerrar as duas...")
    call_logger.log_event("TASKS_ENDING", {
        "done_tasks": len(done),
        "pending_tasks": len(pending),
        "call_duration_ms": round(call_duration, 2)
    })

    # Cancela a outra
    for t in pending:
        t.cancel()
    await asyncio.gather(*pending, return_exceptions=True)

    logger.info(f"[{call_id}] Encerrando conexão do visitante.")
    call_logger.log_call_ended("visitor_connection_closed", call_duration)
    
    # Remover logger para liberar recursos
    CallLoggerManager.remove_logger(call_id)
    
    writer.close()
    await writer.wait_closed()


# ------------------------
# MORADOR
# ------------------------

async def receber_audio_morador(reader: asyncio.StreamReader, call_id: str):
    """
    Versão equivalente para o morador, com controle de estado para evitar retroalimentação.
    """
    call_logger = CallLoggerManager.get_logger(call_id)
    vad = webrtcvad.Vad(2)
    frames = []
    is_speaking = False
    silence_start = None
    speech_start = None
    
    # Para controlar se estamos no modo de escuta ativa
    is_listening_mode = True
    
    # Acessar a sessão para verificar o estado
    session = session_manager.get_session(call_id)
    if not session:
        logger.error(f"[{call_id}] Sessão não encontrada para iniciar recebimento de áudio do morador")
        return
    
    # Flag de buffer para descartar áudio residual após IA falar
    discard_buffer_frames = 0

    while True:
        try:
            header = await reader.readexactly(3)
        except asyncio.IncompleteReadError:
            logger.info(f"[{call_id}] Morador desconectou (EOF).")
            call_logger.log_call_ended("resident_disconnected")
            break

        if not header:
            logger.info(f"[{call_id}] Nenhum dado de header, encerrando (morador).")
            call_logger.log_call_ended("invalid_header_resident")
            break

        kind = header[0]
        length = int.from_bytes(header[1:3], "big")

        audio_chunk = await reader.readexactly(length)
        
        # Verificar o estado atual da sessão
        current_state = session.resident_state
        
        # Se estamos em IA_TURN, significa que a IA está falando com o morador - não processamos
        if current_state == "IA_TURN":
            is_listening_mode = False
            continue  # Pula processamento durante fala da IA
            
        # Período de transição: após IA falar, descartamos alguns frames para evitar eco
        if discard_buffer_frames > 0:
            discard_buffer_frames -= 1
            continue
            
        # Se acabamos de transitar de IA_TURN para USER_TURN, ativamos modo de escuta
        if not is_listening_mode and current_state == "USER_TURN":
            is_listening_mode = True
            discard_buffer_frames = 25  # ~0.5s de áudio para descartar possível eco
            logger.debug(f"[{call_id}] Ativando modo de escuta de morador")
            call_logger.log_event("RESIDENT_LISTENING_MODE_ACTIVATED", {"timestamp": time.time()})
            
            # Limpar quaisquer frames acumulados anteriormente
            frames = []
            is_speaking = False
            silence_start = None
            speech_start = None
            continue
        
        # Processamos VAD apenas quando estamos em modo de escuta
        if is_listening_mode and kind == KIND_SLIN and len(audio_chunk) == 320:
            is_voice = vad.is_speech(audio_chunk, 8000)
            if is_voice:
                frames.append(audio_chunk)
                if not is_speaking:
                    is_speaking = True
                    speech_start = asyncio.get_event_loop().time()
                    logger.debug(f"[{call_id}] Morador começou a falar.")
                    call_logger.log_speech_detected(is_visitor=False)
                silence_start = None
            else:
                if is_speaking:
                    if silence_start is None:
                        silence_start = asyncio.get_event_loop().time()
                    else:
                        silence_duration = asyncio.get_event_loop().time() - silence_start
                        if silence_duration > 2.0:
                            is_speaking = False
                            
                            # Se não temos frames suficientes (< 1s), provavelmente é ruído
                            if len(frames) < 50:  # ~1 segundo de áudio (50 frames de 20ms)
                                logger.debug(f"[{call_id}] Descartando fala curta demais do morador ({len(frames)} frames)")
                                frames = []
                                continue
                            
                            # Calcular duração total da fala
                            speech_duration = (asyncio.get_event_loop().time() - speech_start) * 1000
                            logger.debug(f"[{call_id}] Morador parou de falar após {speech_duration:.0f}ms.")
                            call_logger.log_speech_ended(speech_duration, is_visitor=False)
                            call_logger.log_silence_detected(silence_duration * 1000, is_visitor=False)
                            
                            audio_data = b"".join(frames)
                            frames.clear()
                            
                            # Desativar escuta durante processamento
                            is_listening_mode = False

                            # Log antes da transcrição
                            call_logger.log_transcription_start(len(audio_data), is_visitor=False)
                            
                            # Mudar estado para WAITING durante processamento
                            session.resident_state = "WAITING"
                            
                            # Transcrever com medição de tempo
                            start_time = time.time()
                            texto = await transcrever_audio_async(audio_data)
                            transcription_time = (time.time() - start_time) * 1000
                            
                            if texto:
                                call_logger.log_transcription_complete(texto, transcription_time, is_visitor=False)
                                
                                # Medição do tempo de processamento
                                start_time = time.time()
                                session_manager.process_resident_text(call_id, texto)
                                processing_time = (time.time() - start_time) * 1000
                                
                                call_logger.log_event("RESIDENT_PROCESSING_COMPLETE", {
                                    "text": texto,
                                    "processing_time_ms": round(processing_time, 2)
                                })
                                
                                # O estado pode ser atualizado pelo processamento
                            else:
                                call_logger.log_error("TRANSCRIPTION_FAILED", 
                                                    "Falha ao transcrever áudio do morador", 
                                                    {"audio_size": len(audio_data)})
                                # Voltar ao modo de escuta, já que não foi possível processar
                                is_listening_mode = True
        elif kind != KIND_SLIN or len(audio_chunk) != 320:
            logger.warning(f"[{call_id}] Chunk inválido do morador. kind={kind}, len={len(audio_chunk)}")
            call_logger.log_error("INVALID_CHUNK", 
                                "Chunk de áudio inválido recebido do morador", 
                                {"kind": kind, "length": len(audio_chunk)})

    logger.info(f"[{call_id}] receber_audio_morador terminou.")


async def enviar_mensagens_morador(writer: asyncio.StreamWriter, call_id: str):
    """
    Fica buscando mensagens para o morador, sintetiza e envia via áudio.
    
    Atualiza o estado da sessão durante a fala da IA para evitar retroalimentação.
    """
    call_logger = CallLoggerManager.get_logger(call_id)
    
    # Verificar se a sessão existe
    session = session_manager.get_session(call_id)
    if not session:
        logger.error(f"[{call_id}] Sessão não encontrada para enviar mensagens ao morador")
        return
    
    while True:
        await asyncio.sleep(0.2)
        msg = session_manager.get_message_for_resident(call_id)
        if msg is not None:
            logger.info(f"[{call_id}] Enviando mensagem ao morador: {msg}")
            
            # IMPORTANTE: Mudar estado para IA_TURN antes de começar a falar
            # Isso sinaliza para o VAD parar de processar durante a fala
            old_state = session.resident_state
            session.resident_state = "IA_TURN"
            
            call_logger.log_event("RESIDENT_STATE_CHANGE", {
                "from": old_state,
                "to": "IA_TURN",
                "reason": "ia_speaking_to_resident"
            })
            
            call_logger.log_synthesis_start(msg, is_visitor=False)
            
            # Medir tempo de síntese
            start_time = time.time()
            audio_resposta = await sintetizar_fala_async(msg)
            synthesis_time = (time.time() - start_time) * 1000
            
            # Se falhou na síntese, voltamos ao estado anterior
            if not audio_resposta:
                call_logger.log_error("SYNTHESIS_FAILED", 
                                     "Falha ao sintetizar mensagem para o morador", 
                                     {"message": msg})
                
                # Voltar ao estado anterior
                session.resident_state = old_state
                call_logger.log_event("RESIDENT_STATE_CHANGE", {
                    "from": "IA_TURN",
                    "to": old_state,
                    "reason": "synthesis_failed"
                })
                continue
                
            # Síntese bem-sucedida, enviar áudio
            call_logger.log_synthesis_complete(len(audio_resposta), synthesis_time, is_visitor=False)
            
            # Tempo estimado para reprodução (baseado no tamanho do áudio)
            # A taxa de amostragem é 8000Hz com 16 bits por amostra
            # Aproximadamente (len(audio_resposta) / 16000) segundos de áudio
            playback_duration_ms = (len(audio_resposta) / 16) * 1000
            call_logger.log_event("RESIDENT_ESTIMATED_PLAYBACK_DURATION", {
                "duration_ms": playback_duration_ms,
                "audio_size_bytes": len(audio_resposta)
            })
            
            # Enviar o áudio (isso já registra logs de envio)
            await enviar_audio(writer, audio_resposta, call_id=call_id, origem="Morador")
            
            # Adicionar um pequeno atraso após o envio do áudio para garantir
            # que o áudio seja totalmente reproduzido antes de voltar a escutar
            # Os 0.5s adicionais são para criar um buffer de segurança
            post_audio_delay = 0.5
            await asyncio.sleep(post_audio_delay)
            
            # Mudar de volta para USER_TURN para que o sistema possa escutar o morador
            session.resident_state = "USER_TURN"
            call_logger.log_event("RESIDENT_STATE_CHANGE", {
                "from": "IA_TURN",
                "to": "USER_TURN",
                "reason": "ia_finished_speaking_to_resident"
            })


async def iniciar_servidor_audiosocket_morador(reader, writer):
    header = await reader.readexactly(3)
    kind = header[0]
    length = int.from_bytes(header[1:3], "big")
    call_id_bytes = await reader.readexactly(length)
    call_id = call_id_bytes.hex()

    logger.info(f"[MORADOR] Recebido Call ID: {call_id}")
    
    # Inicializar logger específico para esta chamada
    call_logger = CallLoggerManager.get_logger(call_id)
    call_logger.log_event("CALL_SETUP", {
        "type": "resident",
        "call_id": call_id
    })

    session_manager.create_session(call_id)

    # SAUDAÇÃO MORADOR:
    welcome_msg = "Olá, morador! Você está em ligação com a portaria inteligente."
    call_logger.log_event("GREETING_RESIDENT", {"message": welcome_msg})
    
    session_manager.enfileirar_resident(
        call_id,
        welcome_msg
    )

    task1 = asyncio.create_task(receber_audio_morador(reader, call_id))
    task2 = asyncio.create_task(enviar_mensagens_morador(writer, call_id))

    start_time = time.time()
    done, pending = await asyncio.wait([task1, task2], return_when=asyncio.FIRST_COMPLETED)
    call_duration = (time.time() - start_time) * 1000
    
    logger.info(f"[{call_id}] Alguma tarefa (morador) finalizou, encerrar.")
    call_logger.log_event("RESIDENT_TASKS_ENDING", {
        "done_tasks": len(done),
        "pending_tasks": len(pending),
        "call_duration_ms": round(call_duration, 2)
    })

    for t in pending:
        t.cancel()
    await asyncio.gather(*pending, return_exceptions=True)

    writer.close()
    await writer.wait_closed()
    
    logger.info(f"[{call_id}] Conexão do morador encerrada.")
    call_logger.log_call_ended("resident_connection_closed", call_duration)
    
    # Remover logger para liberar recursos
    CallLoggerManager.remove_logger(call_id)


requirements.txt:
aiohappyeyeballs==2.6.1
aiohttp==3.11.16
aiosignal==1.3.2
alembic==1.15.2
annotated-types==0.7.0
anyio==4.9.0
appdirs==1.4.4
arrow==1.3.0
asgiref==3.8.1
asttokens==3.0.0
asyncio==3.4.3
attrs==25.3.0
auth0-python==4.7.2
azure-cognitiveservices-speech==1.41.1
backoff==2.2.1
bcrypt==4.3.0
beautifulsoup4==4.13.4
blinker==1.9.0
build==1.2.2.post1
cachetools==5.5.2
certifi==2025.1.31
cffi==1.17.1
charset-normalizer==3.4.1
chroma-hnswlib==0.7.6
chromadb==0.5.23
click==8.1.8
cohere==5.15.0
colorama==0.4.6
coloredlogs==15.0.1
crewai==0.108.0
crewai-tools==0.38.1
cryptography==43.0.3
dataclasses-json==0.6.7
decorator==5.2.1
Deprecated==1.2.18
deprecation==2.1.0
diff-match-patch==20230430
distro==1.9.0
docker==7.1.0
docstring_parser==0.16
durationpy==0.9
embedchain==0.1.128
et_xmlfile==2.0.0
executing==2.2.0
Faker==25.9.2
fastapi==0.115.9
fastavro==1.10.0
filelock==3.18.0
flatbuffers==25.2.10
fqdn==1.5.1
frozenlist==1.5.0
fsspec==2025.3.2
google-auth==2.39.0
googleapis-common-protos==1.70.0
gptcache==0.1.44
griffe==0.36.9
grpcio==1.71.0
grpcio-tools==1.71.0
guardrails-ai==0.6.5
guardrails-api-client==0.4.0a1
guardrails_hub_types==0.0.4
h11==0.14.0
h2==4.2.0
hpack==4.1.0
httpcore==1.0.8
httptools==0.6.4
httpx==0.27.2
httpx-sse==0.4.0
huggingface-hub==0.30.2
humanfriendly==10.0
hyperframe==6.1.0
idna==3.10
importlib_metadata==8.6.1
importlib_resources==6.5.2
instructor==1.7.9
ipython==9.1.0
ipython_pygments_lexers==1.1.1
isoduration==20.11.0
jedi==0.19.2
Jinja2==3.1.6
jiter==0.8.2
json5==0.12.0
json_repair==0.41.1
jsonpatch==1.33
jsonpickle==4.0.5
jsonpointer==3.0.0
jsonref==1.1.0
jsonschema==4.23.0
jsonschema-specifications==2024.10.1
kubernetes==32.0.1
lancedb==0.21.2
langchain==0.3.23
langchain-cohere==0.3.5
langchain-community==0.3.21
langchain-core==0.3.52
langchain-experimental==0.3.4
langchain-openai==0.2.14
langchain-text-splitters==0.3.8
langsmith==0.3.31
litellm==1.60.2
lxml==4.9.4
Mako==1.3.10
markdown-it-py==3.0.0
MarkupSafe==3.0.2
marshmallow==3.26.1
matplotlib-inline==0.1.7
mdurl==0.1.2
mem0ai==0.1.91
mmh3==5.1.0
monotonic==1.6
mpmath==1.3.0
multidict==6.4.3
mypy-extensions==1.0.0
networkx==3.4.2
nodeenv==1.9.1
numpy==2.2.4
oauthlib==3.2.2
onnxruntime==1.21.0
openai==1.75.0
openpyxl==3.1.5
opentelemetry-api==1.32.1
opentelemetry-exporter-otlp-proto-common==1.32.1
opentelemetry-exporter-otlp-proto-grpc==1.32.1
opentelemetry-exporter-otlp-proto-http==1.32.1
opentelemetry-instrumentation==0.53b1
opentelemetry-instrumentation-asgi==0.53b1
opentelemetry-instrumentation-fastapi==0.53b1
opentelemetry-proto==1.32.1
opentelemetry-sdk==1.32.1
opentelemetry-semantic-conventions==0.53b1
opentelemetry-util-http==0.53b1
orjson==3.10.16
overrides==7.7.0
packaging==24.2
pandas==2.2.3
parso==0.8.4
pdfminer.six==20250327
pdfplumber==0.11.6
pexpect==4.9.0
pika==1.3.2
pillow==11.2.1
portalocker==2.10.1
posthog==3.25.0
prompt_toolkit==3.0.51
propcache==0.3.1
protobuf==5.29.4
psycopg2-binary==2.9.10
ptyprocess==0.7.0
pure_eval==0.2.3
pyarrow==19.0.1
pyasn1==0.6.1
pyasn1_modules==0.4.2
PyAudio==0.2.14
pycparser==2.22
pydantic==2.11.3
pydantic-settings==2.8.1
pydantic_core==2.33.1
pydash==7.0.7
pydub==0.25.1
Pygments==2.19.1
PyJWT==2.10.1
pypdf==5.4.0
pypdfium2==4.30.1
PyPika==0.48.9
pyproject_hooks==1.2.0
pyright==1.1.399
pysbd==0.3.4
python-dateutil==2.9.0.post0
python-dotenv==1.0.1
pytube==15.0.0
pytz==2024.2
pyvis==0.3.2
PyYAML==6.0.2
qdrant-client==1.13.3
RapidFuzz==3.13.0
redis==5.2.1
referencing==0.36.2
regex==2024.11.6
requests==2.32.3
requests-oauthlib==2.0.0
requests-toolbelt==1.0.0
rfc3339-validator==0.1.4
rfc3986-validator==0.1.1
rich==13.9.4
rpds-py==0.24.0
rsa==4.9.1
rstr==3.2.2
schema==0.7.7
semver==3.0.4
shellingham==1.5.4
six==1.17.0
sniffio==1.3.1
soupsieve==2.6
SQLAlchemy==2.0.40
stack-data==0.6.3
starlette==0.45.3
sympy==1.13.3
tabulate==0.9.0
tenacity==9.1.2
tiktoken==0.9.0
tokenizers==0.20.3
tomli==2.2.1
tomli_w==1.2.0
tqdm==4.66.5
traitlets==5.14.3
typer==0.15.2
types-python-dateutil==2.9.0.20241206
types-requests==2.32.0.20250328
typing-inspect==0.9.0
typing-inspection==0.4.0
typing_extensions==4.12.2
tzdata==2025.2
uri-template==1.3.0
urllib3==2.0.7
uv==0.6.14
uvicorn==0.34.1
uvloop==0.21.0
watchfiles==1.0.5
wcwidth==0.2.13
webcolors==24.11.1
webrtcvad==2.0.10
websocket-client==1.8.0
websockets==12.0
wrapt==1.17.2
wsproto==1.2.0
yarl==1.20.0
zipp==3.21.0
zstandard==0.23.0


config.json:
{
    "greeting": {
        "message": "Condomínio Apoena, em que posso ajudar?",
        "voice": "pt-BR-AntonioNeural",
        "delay_seconds": 2
    },
    "system": {
        "default_state": "STANDBY",
        "silence_threshold_seconds": 2.0,
        "max_transaction_time_seconds": 30
    },
    "audio": {
        "sample_rate": 8000,
        "channels": 1,
        "format": "SLIN",
        "chunk_size": 320
    }
}

session_manager.py:
# session_manager.py

import asyncio
import logging
from typing import Dict, Optional, List
from uuid import uuid4

# Mantenha seu import do crew se quiser, mas não vamos chamar direto aqui
# from ai.crew import process_user_message_with_coordinator

from conversation_flow import ConversationFlow

logger = logging.getLogger(__name__)


class SessionData:
    def __init__(self, session_id: str):
        self.session_id = session_id

        self.visitor_state = "USER_TURN"
        self.resident_state = "STANDBY"

        self.history: List[str] = []

        # Filas de mensagens
        self.visitor_queue: asyncio.Queue = asyncio.Queue()
        self.resident_queue: asyncio.Queue = asyncio.Queue()

        self.intent_data = {}

        # Aqui criamos uma instância do Flow para cada sessão
        self.flow = ConversationFlow()


class SessionManager:
    def __init__(self):
        self.sessions: Dict[str, SessionData] = {}

    def create_session(self, session_id: Optional[str] = None) -> SessionData:
        if not session_id:
            session_id = str(uuid4())

        if session_id not in self.sessions:
            self.sessions[session_id] = SessionData(session_id)
            logger.info(f"[SessionManager] Criada nova sessão: {session_id}")
        return self.sessions[session_id]

    def get_session(self, session_id: str) -> Optional[SessionData]:
        return self.sessions.get(session_id)

    # Métodos p/ enfileirar msgs (chamados no flow)
    def enfileirar_visitor(self, session_id: str, mensagem: str):
        session = self.get_session(session_id)
        if session:
            session.visitor_queue.put_nowait(mensagem)

    def enfileirar_resident(self, session_id: str, mensagem: str):
        session = self.get_session(session_id)
        if session:
            session.resident_queue.put_nowait(mensagem)

    def get_message_for_visitor(self, session_id: str) -> Optional[str]:
        session = self.get_session(session_id)
        if not session:
            return None
        if session.visitor_queue.empty():
            return None
        return session.visitor_queue.get_nowait()

    def get_message_for_resident(self, session_id: str) -> Optional[str]:
        session = self.get_session(session_id)
        if not session:
            return None
        if session.resident_queue.empty():
            return None
        return session.resident_queue.get_nowait()

    # -------------------------------------------------------------
    # Novo process_visitor_text + process_resident_text
    # -------------------------------------------------------------
    def process_visitor_text(self, session_id: str, text: str):
        """
        Agora chamamos o Flow para lidar com a msg do visitante.
        """
        session = self.get_session(session_id)
        if not session:
            session = self.create_session(session_id)

        # logs + history
        logger.info(f"[Session {session_id}] Visitor disse: {text}")
        session.history.append(f"[Visitor] {text}")

        # repassar p/ on_visitor_message
        session.flow.on_visitor_message(session_id, text, self)

    def process_resident_text(self, session_id: str, text: str):
        """
        Agora chamamos o Flow para lidar com a msg do morador.
        """
        session = self.get_session(session_id)
        if not session:
            session = self.create_session(session_id)

        logger.info(f"[Session {session_id}] Resident disse: {text}")
        session.history.append(f"[Resident] {text}")

        session.flow.on_resident_message(session_id, text, self)

    def end_session(self, session_id: str):
        if session_id in self.sessions:
            del self.sessions[session_id]
            logger.info(f"[SessionManager] Sessão {session_id} finalizada e removida.")


state_machine.py:
#!/usr/bin/env python3
# state_machine.py - Máquina de estado simplificada para gerenciar turnos de conversa

import enum
import logging
import uuid
from datetime import datetime
from typing import Callable, List, Dict, Optional
import asyncio  # <-- necessário para as funções assíncronas adicionadas

logger = logging.getLogger(__name__)


class State(enum.Enum):
    """Estados simplificados para a conversa entre usuário e IA."""
    STANDBY = "STANDBY"  # Estado inicial, aguardando nova chamada
    USER_TURN = "USER_TURN"  # Turno do usuário (sistema está ouvindo)
    WAITING = "WAITING"  # Estado intermediário de processamento
    IA_TURN = "IA_TURN"  # Turno da IA (sistema está respondendo)


class StateMachine:
    """
    Máquina de estados simplificada para controlar o fluxo de comunicação
    entre o usuário e a IA em uma chamada.
    """

    def __init__(self):
        self.current_state = State.STANDBY
        self.conversation_id = None
        self.state_change_callbacks: Dict[State, List[Callable]] = {
            state: [] for state in State
        }
        self.transcricoes = []
        self.ultima_resposta = None
        logger.info(f"Máquina de estados inicializada em {self.current_state}")

    def get_state(self) -> State:
        return self.current_state

    def transition_to(self, new_state: State) -> None:
        if new_state == self.current_state:
            logger.debug(f"Ignorando transição redundante para {new_state}")
            return

        old_state = self.current_state
        self.current_state = new_state
        logger.info(f"Transição de estado: {old_state} -> {new_state}")

        if old_state == State.IA_TURN and new_state == State.USER_TURN:
            logger.info("*** IMPORTANTE: Transição de IA_TURN para USER_TURN - ativando escuta ***")
            self.registrar_transcricao_sistema("Sistema ativou escuta - aguardando fala do usuário")
        elif old_state == State.WAITING:
            logger.info(f"Saindo do estado WAITING para {new_state}")
            self.registrar_transcricao_sistema(f"Estado alterado: {old_state.value} -> {new_state.value}")
        if new_state == State.USER_TURN:
            logger.info("*** Sistema pronto para ouvir o usuário ***")

        for callback in self.state_change_callbacks.get(new_state, []):
            try:
                callback()
            except Exception as e:
                logger.error(f"Erro no callback de mudança de estado: {e}")

    def on_state_change(self, state: State, callback: Callable) -> None:
        if state in self.state_change_callbacks:
            self.state_change_callbacks[state].append(callback)

    def is_user_turn(self) -> bool:
        return self.current_state == State.USER_TURN

    def is_ai_turn(self) -> bool:
        return self.current_state == State.IA_TURN

    def is_waiting(self) -> bool:
        return self.current_state == State.WAITING

    def is_standby(self) -> bool:
        return self.current_state == State.STANDBY

    def start_new_conversation(self, standby=False) -> str:
        self.conversation_id = str(uuid.uuid4())
        self.transcricoes = []
        self.ultima_resposta = None

        if not standby:
            self.transition_to(State.USER_TURN)
        else:
            self.transition_to(State.STANDBY)

        logger.info(f"Nova conversa iniciada com ID: {self.conversation_id}")
        return self.conversation_id

    def registrar_transcricao_usuario(self, texto: str) -> None:
        self.transcricoes.append({
            "timestamp": datetime.now().isoformat(),
            "origem": "usuario",
            "texto": texto
        })
        logger.info(f"Transcrição do usuário registrada: {texto}")

    def registrar_transcricao_ia(self, texto: str, resposta_completa: Optional[Dict] = None) -> None:
        self.transcricoes.append({
            "timestamp": datetime.now().isoformat(),
            "origem": "ia",
            "texto": texto
        })
        self.ultima_resposta = resposta_completa
        logger.info(f"Resposta da IA registrada: {texto}")

    def registrar_transcricao_sistema(self, texto: str) -> None:
        self.transcricoes.append({
            "timestamp": datetime.now().isoformat(),
            "origem": "sistema",
            "texto": texto
        })
        logger.info(f"Mensagem do sistema registrada: {texto}")

    def obter_historico_transcricoes(self) -> List[Dict]:
        return self.transcricoes

    def get_conversation_id(self) -> Optional[str]:
        return self.conversation_id

    def end_conversation(self) -> None:
        logger.info(f"Conversa {self.conversation_id} finalizada")
        self.conversation_id = None
        self.transition_to(State.STANDBY)

    # Novas funções adicionadas:
    async def wait_for_state(self, state: State):
        """Aguarda até que o estado especificado seja atingido."""
        while self.current_state != state:
            await asyncio.sleep(0.1)

    async def wait_for_state_change(self):
        """Aguarda até que ocorra uma mudança do estado atual."""
        current_state = self.current_state
        while self.current_state == current_state:
            await asyncio.sleep(0.1)


audio_utils.py:
#!/usr/bin/env python3
# audio_utils.py - Utilitários para manipulação de áudio

from pydub import AudioSegment
from io import BytesIO
import logging

logger = logging.getLogger(__name__)

def converter_bytes_para_wav(dados_slin, sample_rate=8000):
    """
    Converte bytes no formato SLIN para WAV.
    
    Args:
        dados_slin: Bytes de áudio no formato SLIN
        sample_rate: Taxa de amostragem (padrão: 8000 Hz)
        
    Returns:
        Bytes WAV do áudio convertido
    """
    try:
        audio_segment = AudioSegment(
            data=bytes(dados_slin),
            sample_width=2,  # 16 bits = 2 bytes
            frame_rate=sample_rate,
            channels=1
        )
        buffer = BytesIO()
        audio_segment.export(buffer, format='wav')
        return buffer.getvalue()
    except Exception as e:
        logger.error(f"Erro ao converter bytes para WAV: {e}")
        return None

def converter_wav_para_slin(dados_wav, sample_rate=8000):
    """
    Converte bytes WAV para o formato SLIN.
    
    Args:
        dados_wav: Bytes de áudio no formato WAV
        sample_rate: Taxa de amostragem desejada (padrão: 8000 Hz)
        
    Returns:
        Bytes SLIN do áudio convertido
    """
    try:
        audio_segment = AudioSegment.from_file(BytesIO(dados_wav), format="wav")
        audio_segment = audio_segment.set_frame_rate(sample_rate).set_channels(1).set_sample_width(2)
        return audio_segment.raw_data
    except Exception as e:
        logger.error(f"Erro ao converter WAV para SLIN: {e}")
        return None

.gitignore:
# Editors
.vscode/
.idea/

# Vagrant
.vagrant/

# Mac/OSX
.DS_Store

# Windows
Thumbs.db

# Source for the following rules: https://raw.githubusercontent.com/github/gitignore/master/Python.gitignore
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
.python-version

# celery beat schedule file
celerybeat-schedule

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json
__pycache__/*
__pycache__/session_manager.cpython-311.pyc
.env


test_logs.py:
#!/usr/bin/env python3
"""
Script de teste para demonstrar o sistema de logs.
Este script simula uma chamada e gera logs para análise.
"""

import asyncio
import uuid
import time
import logging
from utils.call_logger import CallLoggerManager
import random

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def simulate_call(call_duration=30):
    """Simula uma chamada completa com visitante e morador."""
    # Gerar um ID único para a chamada
    call_id = str(uuid.uuid4())
    logger.info(f"Iniciando chamada simulada com ID: {call_id}")
    
    # Obter o logger para esta chamada
    call_logger = CallLoggerManager.get_logger(call_id)
    call_logger.log_event("CALL_SETUP", {
        "type": "visitor",
        "call_id": call_id
    })
    
    # Simular saudação
    welcome_msg = "Olá, seja bem-vindo! Em que posso ajudar?"
    call_logger.log_event("GREETING", {"message": welcome_msg})
    
    # Simular visitante falando
    await asyncio.sleep(1.5)  # Tempo até o visitante começar a falar
    call_logger.log_speech_detected(is_visitor=True)
    
    # Visitante fala por um tempo
    speech_duration = random.uniform(2.0, 4.0) * 1000  # 2-4 segundos
    await asyncio.sleep(speech_duration / 1000)
    
    # Visitante para de falar, silêncio detectado
    call_logger.log_speech_ended(speech_duration, is_visitor=True)
    call_logger.log_silence_detected(2000, is_visitor=True)
    
    # Simular transcrição do áudio
    audio_size = int(speech_duration * 8)  # Simulação de tamanho de áudio
    call_logger.log_transcription_start(audio_size, is_visitor=True)
    
    # Simular tempo de transcrição
    transcription_time = random.uniform(0.5, 2.0) * 1000  # 500ms - 2s
    await asyncio.sleep(transcription_time / 1000)
    
    visitor_text = "Olá, sou o João e estou aqui para entregar uma encomenda para o apartamento 501 da Renata Oliveira."
    call_logger.log_transcription_complete(visitor_text, transcription_time, is_visitor=True)
    
    # Simular processamento de IA
    call_logger.log_ai_processing_start(visitor_text)
    
    # Simular extração de intenção (tipo)
    call_logger.log_event("INTENT_EXTRACTION_START", {
        "stage": "intent_type",
        "current_intent": "{}"
    })
    
    intent_time = random.uniform(1.0, 3.0) * 1000
    await asyncio.sleep(intent_time / 1000)
    
    call_logger.log_event("INTENT_EXTRACTION_COMPLETE", {
        "stage": "intent_type",
        "result": "entrega",
        "duration_ms": intent_time
    })
    
    # Simular extração de nome
    call_logger.log_event("INTENT_EXTRACTION_START", {
        "stage": "interlocutor_name",
        "current_intent": '{"intent_type": "entrega"}'
    })
    
    name_time = random.uniform(1.0, 2.0) * 1000
    await asyncio.sleep(name_time / 1000)
    
    call_logger.log_event("INTENT_EXTRACTION_COMPLETE", {
        "stage": "interlocutor_name",
        "result": "João",
        "duration_ms": name_time
    })
    
    # Simular extração de apartamento e morador
    call_logger.log_event("INTENT_EXTRACTION_START", {
        "stage": "apartment_and_resident",
        "current_intent": '{"intent_type": "entrega", "interlocutor_name": "João"}'
    })
    
    apt_time = random.uniform(1.0, 2.0) * 1000
    await asyncio.sleep(apt_time / 1000)
    
    call_logger.log_event("INTENT_EXTRACTION_COMPLETE", {
        "stage": "apartment_and_resident",
        "result": "apt: 501, resident: Renata Oliveira",
        "duration_ms": apt_time
    })
    
    # Simular validação fuzzy
    call_logger.log_event("FUZZY_VALIDATION_START", {
        "intent": '{"intent_type": "entrega", "interlocutor_name": "João", "apartment_number": "501", "resident_name": "Renata Oliveira"}'
    })
    
    fuzzy_time = random.uniform(0.1, 0.5) * 1000
    await asyncio.sleep(fuzzy_time / 1000)
    
    call_logger.log_event("FUZZY_VALIDATION_COMPLETE", {
        "status": "válido",
        "match_name": "Renata Oliveira",
        "voip_number": "1003030",
        "duration_ms": fuzzy_time
    })
    
    # Finalizar processamento de IA
    ai_total_time = intent_time + name_time + apt_time + fuzzy_time
    response = {
        "mensagem": "Entrega registrada para Renata Oliveira no apartamento 501. Vou chamar a moradora.",
        "dados": {
            "intent_type": "entrega",
            "interlocutor_name": "João",
            "apartment_number": "501",
            "resident_name": "Renata Oliveira"
        },
        "valid_for_action": True
    }
    
    call_logger.log_ai_processing_complete(response, ai_total_time)
    
    # Simular resposta para o visitante
    call_logger.log_synthesis_start(response["mensagem"], is_visitor=True)
    
    synthesis_time = random.uniform(0.5, 1.5) * 1000
    await asyncio.sleep(synthesis_time / 1000)
    
    audio_size = len(response["mensagem"]) * 100  # Tamanho simulado do áudio
    call_logger.log_synthesis_complete(audio_size, synthesis_time, is_visitor=True)
    
    # Simular chamada para o morador
    call_logger.log_event("CALL_MORADOR", {
        "voip_number": "1003030",
        "attempt": 1
    })
    
    await asyncio.sleep(2.0)  # Tempo até morador atender
    
    # Morador atende
    call_logger.log_event("MORADOR_CONNECTED", {
        "voip_number": "1003030"
    })
    
    # Saudação para o morador
    morador_welcome = "Olá, morador! Há uma entrega para você na portaria."
    call_logger.log_synthesis_start(morador_welcome, is_visitor=False)
    
    synthesis_time = random.uniform(0.5, 1.5) * 1000
    await asyncio.sleep(synthesis_time / 1000)
    
    audio_size = len(morador_welcome) * 100
    call_logger.log_synthesis_complete(audio_size, synthesis_time, is_visitor=False)
    
    # Morador responde
    await asyncio.sleep(1.0)
    call_logger.log_speech_detected(is_visitor=False)
    
    speech_duration = random.uniform(1.0, 2.0) * 1000
    await asyncio.sleep(speech_duration / 1000)
    
    call_logger.log_speech_ended(speech_duration, is_visitor=False)
    call_logger.log_silence_detected(2000, is_visitor=False)
    
    # Transcrição da resposta do morador
    audio_size = int(speech_duration * 8)
    call_logger.log_transcription_start(audio_size, is_visitor=False)
    
    transcription_time = random.uniform(0.5, 1.5) * 1000
    await asyncio.sleep(transcription_time / 1000)
    
    morador_text = "Sim, pode deixar entrar."
    call_logger.log_transcription_complete(morador_text, transcription_time, is_visitor=False)
    
    # Processamento da resposta do morador
    start_time = time.time()
    await asyncio.sleep(0.2)  # Tempo de processamento (simples)
    processing_time = (time.time() - start_time) * 1000
    
    call_logger.log_event("RESIDENT_PROCESSING_COMPLETE", {
        "text": morador_text,
        "processing_time_ms": processing_time
    })
    
    # Resposta final para o visitante
    final_message = "Morador autorizou sua entrada! Pode entrar."
    call_logger.log_synthesis_start(final_message, is_visitor=True)
    
    synthesis_time = random.uniform(0.5, 1.0) * 1000
    await asyncio.sleep(synthesis_time / 1000)
    
    audio_size = len(final_message) * 100
    call_logger.log_synthesis_complete(audio_size, synthesis_time, is_visitor=True)
    
    # Terminar chamada
    await asyncio.sleep(1.0)
    call_logger.log_call_ended("call_completed", call_duration * 1000)
    
    # Remover logger
    CallLoggerManager.remove_logger(call_id)
    
    logger.info(f"Chamada simulada finalizada: {call_id}")
    return call_id


async def simulate_error_call():
    """Simula uma chamada com erros."""
    call_id = str(uuid.uuid4())
    logger.info(f"Iniciando chamada com erros - ID: {call_id}")
    
    call_logger = CallLoggerManager.get_logger(call_id)
    call_logger.log_event("CALL_SETUP", {
        "type": "visitor",
        "call_id": call_id
    })
    
    # Simular visitante falando
    await asyncio.sleep(1.0)
    call_logger.log_speech_detected(is_visitor=True)
    
    speech_duration = random.uniform(1.0, 3.0) * 1000
    await asyncio.sleep(speech_duration / 1000)
    
    call_logger.log_speech_ended(speech_duration, is_visitor=True)
    
    # Simular erro na transcrição
    audio_size = int(speech_duration * 8)
    call_logger.log_transcription_start(audio_size, is_visitor=True)
    
    await asyncio.sleep(1.0)
    
    call_logger.log_error("TRANSCRIPTION_FAILED", 
                        "Falha ao transcrever áudio do visitante", 
                        {"audio_size": audio_size, "reason": "Audio clarity too low"})
    
    # Simular mensagem de erro para o visitante
    error_message = "Desculpe, não consegui entender. Pode repetir por favor?"
    call_logger.log_synthesis_start(error_message, is_visitor=True)
    
    synthesis_time = random.uniform(0.5, 1.0) * 1000
    await asyncio.sleep(synthesis_time / 1000)
    
    audio_size = len(error_message) * 100
    call_logger.log_synthesis_complete(audio_size, synthesis_time, is_visitor=True)
    
    # Terminar chamada
    await asyncio.sleep(1.0)
    call_logger.log_call_ended("transcription_error", 5000)
    
    # Remover logger
    CallLoggerManager.remove_logger(call_id)
    
    logger.info(f"Chamada com erro finalizada: {call_id}")
    return call_id


async def main():
    """Executa simulações de chamada."""
    print("Iniciando simulações de chamadas...")
    
    # Simular 3 chamadas bem-sucedidas
    calls = []
    for i in range(3):
        calls.append(simulate_call(random.randint(20, 40)))
    
    # Simular 1 chamada com erro
    calls.append(simulate_error_call())
    
    # Executar todas as chamadas em paralelo
    call_ids = await asyncio.gather(*calls)
    
    print("\nSimulações concluídas!")
    print("IDs das chamadas simuladas:")
    for call_id in call_ids:
        print(f"  - {call_id}")
    
    print(f"\nOs logs foram gerados na pasta 'logs/'")
    print("Para analisar os logs, execute:")
    print(f"  python utils/log_analyzer.py --call_id {call_ids[0]}")
    print("  ou")
    print("  python utils/log_analyzer.py --all --summary")


if __name__ == "__main__":
    asyncio.run(main())

microfone_client.py:
#!/usr/bin/env python3
import socket, struct, threading, pyaudio, logging, uuid, time

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')

KIND_ID, KIND_SLIN, KIND_HANGUP = 0x01, 0x10, 0x00

class AudioSocketClient:
    def __init__(self, host='127.0.0.1', port=8080):  # Mudando para localhost
        self.host, self.port = host, port
        self.call_id = uuid.uuid4().bytes
        self.sample_rate, self.channels, self.chunk_size = 8000, 1, 320
        self.format = pyaudio.paInt16
        self.running = False

    def connect(self):
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        logging.info(f"Tentando conectar a {self.host}:{self.port}...")
        self.socket.connect((self.host, self.port))
        
        # Enviar ID da chamada
        call_uuid = uuid.UUID(bytes=self.call_id)
        logging.info(f"Enviando ID da chamada: {call_uuid}")
        self.socket.sendall(struct.pack('>B H', KIND_ID, len(self.call_id)) + self.call_id)
        
        logging.info("Conectado ao servidor! Iniciando transmissão de áudio...")
        self.running = True
        
        # Iniciar threads para envio e recebimento de áudio
        self.send_thread = threading.Thread(target=self.send_audio, name="SendAudio")
        self.send_thread.daemon = True
        self.send_thread.start()
        
        self.receive_thread = threading.Thread(target=self.receive_audio, name="ReceiveAudio")
        self.receive_thread.daemon = True
        self.receive_thread.start()

    def send_audio(self):
        p = pyaudio.PyAudio()
        stream = p.open(format=self.format, channels=self.channels, rate=self.sample_rate, input=True, frames_per_buffer=self.chunk_size//2)
        try:
            while self.running:
                data = stream.read(self.chunk_size//2, exception_on_overflow=False)
                self.socket.sendall(struct.pack('>B H', KIND_SLIN, len(data)) + data)
        except Exception as e:
            logging.error(f"Erro no envio de áudio: {e}")
            self.running = False
        stream.stop_stream()
        stream.close()
        p.terminate()

    def receive_audio(self):
        p = pyaudio.PyAudio()
        stream = p.open(format=self.format, channels=self.channels, rate=self.sample_rate, output=True)
        last_audio_time = 0
        audio_count = 0
        try:
            while self.running:
                header = self.socket.recv(3)
                if not header: 
                    logging.warning("Recebido header vazio, encerrando conexão...")
                    break
                    
                kind, length = header[0], struct.unpack('>H', header[1:3])[0]
                payload = self.socket.recv(length)
                
                if kind == KIND_SLIN:
                    stream.write(payload)
                    audio_count += 1
                    
                    # A cada 50 pacotes de áudio, mostramos um indicador
                    if audio_count % 50 == 0:
                        current_time = time.time()
                        if last_audio_time > 0:
                            rate = 50 / (current_time - last_audio_time)
                            logging.info(f"Recebendo áudio: {rate:.1f} pacotes/s")
                        last_audio_time = current_time
                else:
                    logging.debug(f"Recebido pacote não-SLIN: kind={kind}, length={length}")
                    
        except ConnectionResetError:
            logging.error("Conexão fechada pelo servidor")
            self.running = False
        except Exception as e:
            logging.error(f"Erro no recebimento de áudio: {e}")
            self.running = False
            
        logging.info("Thread de recebimento encerrada")
        stream.stop_stream()
        stream.close()
        p.terminate()

    def disconnect(self):
        self.running = False
        try:
            # Verificar se o socket está conectado antes de tentar enviar dados
            if hasattr(self, 'socket') and self.socket:
                try:
                    self.socket.sendall(struct.pack('>B H', KIND_HANGUP, 0))
                except (OSError, BrokenPipeError) as e:
                    logging.warning(f"Não foi possível enviar comando de hangup: {e}")
                
                try:
                    self.socket.close()
                except Exception as e:
                    logging.warning(f"Erro ao fechar socket: {e}")
                    
            logging.info("Desconectado do servidor.")
        except Exception as e:
            logging.error(f"Erro durante a desconexão: {e}")

if __name__ == "__main__":
    import argparse
    
    # Adicionar opções de linha de comando
    parser = argparse.ArgumentParser(description='Cliente de microfone para AudioSocket')
    parser.add_argument('--host', default='127.0.0.1', help='Endereço do servidor (padrão: 127.0.0.1)')
    parser.add_argument('--port', type=int, default=8080, help='Porta do servidor (padrão: 8080)')
    args = parser.parse_args()
    
    # Usar os valores fornecidos pelo usuário ou os padrões
    logging.info(f"Conectando ao servidor {args.host}:{args.port}")
    client = AudioSocketClient(host=args.host, port=args.port)
    
    try:
        client.connect()
        logging.info("Pressione Ctrl+C para encerrar")
        
        # Loop para manter o programa em execução
        while client.running:
            import time
            time.sleep(0.1)  # Pequeno delay para não consumir CPU
            
    except KeyboardInterrupt:
        logging.info("Encerrando conexão...")
    except ConnectionRefusedError:
        logging.error(f"Não foi possível conectar ao servidor {args.host}:{args.port}")
        logging.error("Verifique se o servidor está em execução")
    except Exception as e:
        logging.error(f"Erro: {e}")
    finally:
        if client.running:
            client.disconnect()


code_gpt.py:
import os

IGNORE = {'__pycache__', '.env', '.git', '.idea', 'audio', "*.md", "logs"}

def list_structure(base_path, prefix=""):
    tree = ""
    items = sorted(os.listdir(base_path))
    for item in items:
        if item in IGNORE:
            continue
        path = os.path.join(base_path, item)
        if os.path.isdir(path):
            tree += f"{prefix}{item}/\n"
            tree += list_structure(path, prefix + "    ")
        else:
            tree += f"{prefix}{item}\n"
    return tree

def list_code_files(base_path):
    code = ""
    for root, dirs, files in os.walk(base_path):
        dirs[:] = [d for d in dirs if d not in IGNORE]
        for file in files:
            if file in IGNORE:
                continue
            file_path = os.path.join(root, file)
            rel_path = os.path.relpath(file_path, base_path)
            code += f"\n{rel_path}:\n"
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    code += f.read() + "\n"
            except Exception as e:
                code += f"Erro ao ler arquivo: {e}\n"
    return code

def main():
    base_path = "."
    structure = list_structure(base_path)
    code_files = list_code_files(base_path)

    with open("code.txt", "w", encoding="utf-8") as f:
        f.write("Estrutura do projeto:\n")
        f.write(structure)
        f.write("\nCódigo fonte:\n")
        f.write(code_files)

    print("Arquivo 'code.txt' criado com sucesso.")

if __name__ == "__main__":
    main()


conversation_flow.py:
# conversation_flow.py

import logging
from enum import Enum, auto
from typing import Optional

from ai.crew import process_user_message_with_coordinator
from ai.tools import validar_intent_com_fuzzy

import pika
import json
import asyncio  ### PASSO 2: precisamos de asyncio

logger = logging.getLogger(__name__)

class FlowState(Enum):
    COLETANDO_DADOS = auto()
    VALIDADO = auto()
    CHAMANDO_MORADOR = auto()
    ESPERANDO_MORADOR = auto()
    FINALIZADO = auto()

class ConversationFlow:
    """
    Define o fluxo de interação entre visitante e morador, passo a passo.
    """

    def __init__(self):
        self.state = FlowState.COLETANDO_DADOS
        self.intent_data = {}
        self.is_fuzzy_valid = False
        self.voip_number_morador: Optional[str] = None

        # Para controlar tentativas de chamada
        self.tentativas_chamada = 0  ### PASSO 2

    # ---------------
    # VISITOR
    # ---------------
    def on_visitor_message(self, session_id: str, text: str, session_manager):
        logger.debug(f"[Flow] Visitor message in state={self.state}, text='{text}'")

        if self.state == FlowState.COLETANDO_DADOS:
            try:
                # Adicionar timeout para prevenção de bloqueio
                result = process_user_message_with_coordinator(session_id, text)
                logger.debug(f"[Flow] result IA: {result}")
                
                # Verificar se o resultado é None ou está vazio
                if result is None:
                    logger.error(f"[Flow] IA retornou resultado None para '{text}'")
                    session_manager.enfileirar_visitor(
                        session_id,
                        "Desculpe, tive um problema ao processar sua mensagem. Por favor, repita ou informe novamente seus dados."
                    )
                    return
                
                # Atualiza self.intent_data com quaisquer dados retornados
                if "dados" in result:
                    for k, v in result["dados"].items():
                        self.intent_data[k] = v
                else:
                    logger.warning(f"[Flow] Resultado sem campo 'dados': {result}")
                    
                # Log de segurança para entender o estado atual
                logger.info(f"[Flow] Dados acumulados: {self.intent_data}")

                # Se veio alguma mensagem para o visitante, enfileira
                if "mensagem" in result:
                    session_manager.enfileirar_visitor(session_id, result["mensagem"])
                else:
                    # Mensagem de fallback caso não tenha mensagem no resultado
                    session_manager.enfileirar_visitor(
                        session_id,
                        "Por favor, continue informando os dados necessários."
                    )

                # Se valid_for_action, tentamos fuzzy
                if result.get("valid_for_action"):
                    # Verificação de segurança nos dados antes da validação fuzzy
                    apt = self.intent_data.get("apartment_number", "").strip()
                    resident = self.intent_data.get("resident_name", "").strip()
                    
                    if not apt or not resident:
                        logger.warning(f"[Flow] Dados incompletos antes do fuzzy: apt={apt}, resident={resident}")
                        session_manager.enfileirar_visitor(
                            session_id,
                            "Preciso do número do apartamento e nome do morador para continuar."
                        )
                        return
                        
                    fuzzy_res = validar_intent_com_fuzzy(self.intent_data)
                    logger.info(f"[Flow] fuzzy= {fuzzy_res}")

                    if fuzzy_res["status"] == "válido":
                        self.is_fuzzy_valid = True
                        self.voip_number_morador = fuzzy_res.get("voip_number")
                        
                        # Atualizar o intent_data com o nome correto do apartamento/morador
                        if "apartment_number" in fuzzy_res:
                            self.intent_data["apartment_number"] = fuzzy_res["apartment_number"]
                        if "match_name" in fuzzy_res:
                            self.intent_data["resident_name"] = fuzzy_res["match_name"]
                            
                        self.state = FlowState.VALIDADO

                        # Mensagem curta ao visitante:
                        session_manager.enfileirar_visitor(
                            session_id,
                            "Ok, vamos entrar em contato com o morador. Aguarde, por favor."
                        )

                        # Avança para CHAMANDO_MORADOR
                        self.state = FlowState.CHAMANDO_MORADOR
                        self.chamar_morador(session_id, session_manager)
                    else:
                        # Mensagem com mais detalhes sobre o motivo da falha
                        if "best_match" in fuzzy_res and fuzzy_res.get("best_score", 0) > 50:
                            session_manager.enfileirar_visitor(
                                session_id,
                                f"Encontrei um morador similar ({fuzzy_res['best_match']}), mas preciso que confirme o apartamento e nome corretos."
                            )
                        else:
                            session_manager.enfileirar_visitor(
                                session_id,
                                f"Desculpe, dados inválidos: {fuzzy_res.get('reason','motivo')}. Vamos tentar novamente."
                            )
            except Exception as e:
                # Tratamento de erro global para evitar travar o fluxo
                logger.error(f"[Flow] Erro no processamento: {str(e)}")
                session_manager.enfileirar_visitor(
                    session_id,
                    "Desculpe, ocorreu um erro ao processar sua solicitação. Por favor, tente novamente."
                )

        elif self.state == FlowState.CHAMANDO_MORADOR:
            session_manager.enfileirar_visitor(
                session_id,
                "Ainda estou tentando chamar o morador, aguarde..."
            )

        elif self.state == FlowState.ESPERANDO_MORADOR:
            session_manager.enfileirar_visitor(
                session_id,
                "O morador está na linha. Aguarde a resposta."
            )

        elif self.state == FlowState.FINALIZADO:
            session_manager.enfileirar_visitor(session_id, "A chamada já foi encerrada. Obrigado.")
        else:
            session_manager.enfileirar_visitor(session_id, "Aguarde, por favor.")

    # ---------------
    # RESIDENT
    # ---------------
    def on_resident_message(self, session_id: str, text: str, session_manager):
        logger.debug(f"[Flow] Resident message in state={self.state}, text='{text}'")

        if self.state == FlowState.CHAMANDO_MORADOR:
            # Significa que o morador atendeu e começou a falar
            self.state = FlowState.ESPERANDO_MORADOR
            session_manager.enfileirar_resident(session_id, "Olá, morador! O visitante pediu acesso...")
            session_manager.enfileirar_visitor(session_id, "O morador atendeu. Aguarde a resposta.")

        elif self.state == FlowState.ESPERANDO_MORADOR:
            # Esperamos SIM ou NÃO
            lower_text = text.lower()
            if "sim" in lower_text:
                session_manager.enfileirar_visitor(session_id, "Morador autorizou sua entrada!")
                self.state = FlowState.FINALIZADO
                self._finalizar(session_id, session_manager)
            elif "não" in lower_text or "nao" in lower_text:
                session_manager.enfileirar_visitor(session_id, "Morador negou a entrada.")
                self.state = FlowState.FINALIZADO
                self._finalizar(session_id, session_manager)
            else:
                session_manager.enfileirar_resident(session_id, "Não entendi. Responda SIM ou NÃO.")

        elif self.state == FlowState.FINALIZADO:
            session_manager.enfileirar_resident(session_id, "O fluxo já foi finalizado. Obrigado.")

        elif self.state == FlowState.COLETANDO_DADOS:
            session_manager.enfileirar_resident(
                session_id,
                "Ainda estamos coletando dados do visitante. Aguarde um instante..."
            )

        else:
            # Estado VALIDADO ou outro
            session_manager.enfileirar_resident(session_id, "Ainda estou preparando a chamada, aguarde.")

    # ----------------------------------------------------
    #  CHAMAR MORADOR via AMQP
    # ----------------------------------------------------
    def chamar_morador(self, session_id: str, session_manager):
        """
        Envia a mensagem AMQP para gerar a ligação com o morador.
        E agenda a verificação da conexão em 10s.
        """
        if not self.voip_number_morador:
            logger.warning("[Flow] voip_number_morador está vazio, não posso discar.")
            return

        # Primeira tentativa ou re-tentativa
        self.tentativas_chamada += 1

        session_manager.enfileirar_visitor(
            session_id,
            f"Discando para {self.voip_number_morador}... (Tentativa {self.tentativas_chamada})"
        )

        try:
            self.enviar_clicktocall(self.voip_number_morador, session_id)
            logger.info(f"[Flow] AMQP enviado para origin={self.voip_number_morador}, tentativa={self.tentativas_chamada}")
        except Exception as e:
            logger.error(f"[Flow] Falha ao enviar AMQP: {e}")
            session_manager.enfileirar_visitor(
                session_id,
                "Não foi possível chamar o morador. Tente novamente mais tarde."
            )
            self.state = FlowState.FINALIZADO
            self._finalizar(session_id, session_manager)
            return

        ### PASSO 2: Agendar a verificação em 10s
        loop = asyncio.get_event_loop()
        loop.create_task(self.monitorar_morador_conexao(session_id, session_manager))


    async def monitorar_morador_conexao(self, session_id: str, session_manager):
        """
        Aguarda 10s para ver se o estado mudou para ESPERANDO_MORADOR.
        Se não mudou, tenta chamar de novo (até 2 tentativas).
        Se mesmo assim não mudou, finaliza.
        """
        await asyncio.sleep(10)

        # Verifica se neste meio tempo o morador atendeu (ESPERANDO_MORADOR)
        if self.state == FlowState.ESPERANDO_MORADOR:
            logger.info("[Flow] Morador conectou antes dos 10s. Não precisa retentar.")
            return  # Está tudo bem.

        # Se chegou aqui, ainda está CHAMANDO_MORADOR e não conectou.
        if self.tentativas_chamada < 2:
            # Tentar novamente
            logger.info("[Flow] Morador não conectou em 10s. Vamos tentar ligar de novo.")
            self.chamar_morador(session_id, session_manager)
        else:
            # 2 tentativas falharam
            logger.info("[Flow] Morador não conectou após duas tentativas.")
            session_manager.enfileirar_visitor(session_id,
                "Não foi possível falar com o morador. Encaminharemos para a central e encerraremos a chamada."
            )
            self.state = FlowState.FINALIZADO
            self._finalizar(session_id, session_manager)


    def enviar_clicktocall(self, morador_voip_number: str, guid: str):
        """
        Ajuste host/credentials/queue etc. conforme sua infra.
        """
        rabbit_host = 'mqdev.tecnofy.com.br'
        rabbit_user = 'fonia'
        rabbit_password = 'fonia123'
        rabbit_vhost = 'DEV'
        queue_name = 'voip1-in'

        credentials = pika.PlainCredentials(rabbit_user, rabbit_password)
        parameters = pika.ConnectionParameters(
            host=rabbit_host,
            virtual_host=rabbit_vhost,
            credentials=credentials
        )

        connection = pika.BlockingConnection(parameters)
        channel = connection.channel()
        channel.queue_declare(queue=queue_name, durable=True)

        payload = {
            "data": {
                "destiny": "IA",
                "guid": guid,
                "license": "123456789012",
                "origin": morador_voip_number
            },
            "operation": {
                "eventcode": "8001",
                "guid": "cmd-" + guid,
                "msg": "",
                "timestamp": 1740696805,
                "type": "clicktocall"
            }
        }

        channel.basic_publish(
            exchange='',
            routing_key=queue_name,
            body=json.dumps(payload)
        )
        logger.info(f"[Flow] Mensagem AMQP enviada: origin={morador_voip_number}, guid={guid}")
        connection.close()

    # ----------------------------------------------------
    # FINALIZAR (chamar end_session, etc.)
    # ----------------------------------------------------
    def _finalizar(self, session_id: str, session_manager):
        """
        Encerra a conversa e remove a sessão (se preferir).
        """
        session_manager.enfileirar_resident(session_id, "Conversa encerrada.")
        session_manager.enfileirar_visitor(session_id, "Conversa encerrada. Obrigado.")

        session_manager.end_session(session_id)


main.py:
import asyncio
import logging
from dotenv import load_dotenv
from audiosocket_handler import iniciar_servidor_audiosocket_visitante, iniciar_servidor_audiosocket_morador
logging.basicConfig(level=logging.INFO)

load_dotenv()

async def main():
    server_visitante = await asyncio.start_server(iniciar_servidor_audiosocket_visitante, '0.0.0.0', 8080)
    server_morador = await asyncio.start_server(iniciar_servidor_audiosocket_morador, '0.0.0.0', 8081)

    logging.info("Servidor visitante: 0.0.0.0:8080")
    logging.info("Servidor morador:   0.0.0.0:8081")

    async with server_visitante, server_morador:
        await asyncio.gather(
            server_visitante.serve_forever(),
            server_morador.serve_forever()
        )

if __name__ == "__main__":
    asyncio.run(main())


speech_service.py:
import asyncio
from io import BytesIO

from audio_utils import converter_bytes_para_wav, converter_wav_para_slin
import azure.cognitiveservices.speech as speechsdk
import os
from pydub import AudioSegment

async def transcrever_audio_async(dados_audio_slin):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, transcrever_audio, dados_audio_slin)

async def sintetizar_fala_async(texto):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, sintetizar_fala, texto)

def transcrever_audio(dados_audio_slin):
    audio_wav = converter_bytes_para_wav(dados_audio_slin, 8000)
    if not audio_wav:
        return None
    audio_segment = AudioSegment.from_file(BytesIO(audio_wav), format="wav")
    audio_segment = audio_segment.set_frame_rate(16000)
    buffer = BytesIO()
    audio_segment.export(buffer, format='wav')
    audio_wav_16k = buffer.getvalue()
    speech_config = speechsdk.SpeechConfig(subscription=os.getenv('AZURE_SPEECH_KEY'), region=os.getenv('AZURE_SPEECH_REGION'))
    speech_config.speech_recognition_language = 'pt-BR'
    audio_stream = speechsdk.audio.PushAudioInputStream()
    audio_stream.write(audio_wav_16k)
    audio_stream.close()
    audio_config = speechsdk.audio.AudioConfig(stream=audio_stream)
    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)
    result = recognizer.recognize_once()
    return result.text if result.reason == speechsdk.ResultReason.RecognizedSpeech else None

def sintetizar_fala(texto):
    speech_config = speechsdk.SpeechConfig(subscription=os.getenv('AZURE_SPEECH_KEY'), region=os.getenv('AZURE_SPEECH_REGION'))
    speech_config.speech_synthesis_language = 'pt-BR'
    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)
    result = synthesizer.speak_text_async(texto).get()
    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        return converter_wav_para_slin(result.audio_data, 8000)
    return None


utils/log_analyzer.py:
#!/usr/bin/env python3
"""
Analisador de logs das chamadas.
Este script processa os arquivos de log das chamadas para gerar relatórios
de desempenho e identificar possíveis gargalos.
"""

import json
import os
import sys
import glob
import re
from datetime import datetime
from typing import Dict, List, Tuple, Any
import statistics
import argparse

def parse_log_line(line: str) -> Dict[str, Any]:
    """
    Parse uma linha de log no formato:
    2023-04-23 15:30:45.123 | INFO | EVENT_TYPE | {"key": "value", ...}
    
    Retorna um dicionário com timestamp, level, event_type e data.
    """
    pattern = r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\.\d{3}) \| (\w+) \| (\w+) \| (.+)'
    match = re.match(pattern, line)
    
    if not match:
        return None
    
    timestamp_str, level, event_type, data_str = match.groups()
    timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S.%f')
    
    try:
        data = json.loads(data_str)
    except json.JSONDecodeError:
        data = {"raw_message": data_str}
    
    return {
        "timestamp": timestamp,
        "level": level,
        "event_type": event_type,
        "data": data
    }

def load_log_file(filepath: str) -> List[Dict[str, Any]]:
    """
    Carrega um arquivo de log e retorna uma lista de eventos parseados.
    """
    events = []
    with open(filepath, 'r', encoding='utf-8') as f:
        for line in f:
            parsed = parse_log_line(line.strip())
            if parsed:
                events.append(parsed)
    
    return events

def calculate_statistics(values: List[float]) -> Dict[str, float]:
    """
    Calcula estatísticas básicas para uma lista de valores.
    """
    if not values:
        return {
            "min": 0,
            "max": 0,
            "avg": 0,
            "median": 0,
            "p90": 0,
            "p95": 0,
            "p99": 0
        }
    
    values = sorted(values)
    n = len(values)
    
    return {
        "min": min(values),
        "max": max(values),
        "avg": sum(values) / n,
        "median": values[n // 2] if n % 2 else (values[n // 2 - 1] + values[n // 2]) / 2,
        "p90": values[int(n * 0.9)],
        "p95": values[int(n * 0.95)],
        "p99": values[int(n * 0.99)] if n >= 100 else values[-1]
    }

def analyze_transcription_times(events: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Analisa os tempos de transcrição de áudio.
    """
    times = []
    visitor_times = []
    resident_times = []
    
    for i, event in enumerate(events):
        if event["event_type"] == "TRANSCRIPTION_COMPLETE":
            duration = event["data"].get("duration_ms", 0)
            times.append(duration)
            
            if event["data"].get("source") == "visitor":
                visitor_times.append(duration)
            else:
                resident_times.append(duration)
    
    return {
        "all": calculate_statistics(times),
        "visitor": calculate_statistics(visitor_times),
        "resident": calculate_statistics(resident_times)
    }

def analyze_synthesis_times(events: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Analisa os tempos de síntese de áudio.
    """
    times = []
    visitor_times = []
    resident_times = []
    
    for i, event in enumerate(events):
        if event["event_type"] == "SYNTHESIS_COMPLETE":
            duration = event["data"].get("duration_ms", 0)
            times.append(duration)
            
            if event["data"].get("target") == "visitor":
                visitor_times.append(duration)
            else:
                resident_times.append(duration)
    
    return {
        "all": calculate_statistics(times),
        "visitor": calculate_statistics(visitor_times),
        "resident": calculate_statistics(resident_times)
    }

def analyze_ai_processing_times(events: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Analisa os tempos de processamento da IA.
    """
    total_times = []
    intent_extraction_times = {
        "intent_type": [],
        "interlocutor_name": [],
        "apartment_and_resident": []
    }
    fuzzy_validation_times = []
    
    for i, event in enumerate(events):
        if event["event_type"] == "AI_PROCESSING_COMPLETE":
            duration = event["data"].get("duration_ms", 0)
            total_times.append(duration)
        
        elif event["event_type"] == "INTENT_EXTRACTION_COMPLETE":
            duration = event["data"].get("duration_ms", 0)
            stage = event["data"].get("stage")
            if stage in intent_extraction_times:
                intent_extraction_times[stage].append(duration)
        
        elif event["event_type"] == "FUZZY_VALIDATION_COMPLETE":
            duration = event["data"].get("duration_ms", 0)
            fuzzy_validation_times.append(duration)
    
    return {
        "total": calculate_statistics(total_times),
        "intent_extraction": {
            "intent_type": calculate_statistics(intent_extraction_times["intent_type"]),
            "interlocutor_name": calculate_statistics(intent_extraction_times["interlocutor_name"]),
            "apartment_and_resident": calculate_statistics(intent_extraction_times["apartment_and_resident"])
        },
        "fuzzy_validation": calculate_statistics(fuzzy_validation_times)
    }

def analyze_vad_performance(events: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Analisa o desempenho da detecção de voz (VAD).
    """
    speech_durations = []
    silence_durations = []
    
    for i, event in enumerate(events):
        if event["event_type"] == "SPEECH_ENDED":
            duration = event["data"].get("duration_ms", 0)
            speech_durations.append(duration)
        
        elif event["event_type"] == "SILENCE_DETECTED":
            duration = event["data"].get("duration_ms", 0)
            silence_durations.append(duration)
    
    return {
        "speech_durations": calculate_statistics(speech_durations),
        "silence_durations": calculate_statistics(silence_durations)
    }

def analyze_call_durations(events: List[Dict[str, Any]]) -> Dict[str, float]:
    """
    Analisa a duração total das chamadas.
    """
    call_start = None
    call_end = None
    
    for event in events:
        if event["event_type"] == "CALL_STARTED":
            call_start = event["timestamp"]
        elif event["event_type"] == "CALL_ENDED":
            call_end = event["timestamp"]
    
    if call_start and call_end:
        return (call_end - call_start).total_seconds() * 1000
    
    return 0

def analyze_errors(events: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Analisa os erros registrados durante a chamada.
    """
    errors = []
    
    for event in events:
        if event["event_type"] == "ERROR":
            errors.append({
                "timestamp": event["timestamp"],
                "error_type": event["data"].get("error_type", "unknown"),
                "message": event["data"].get("message", ""),
                "details": event["data"].get("details", {})
            })
    
    return errors

def analyze_log_file(filepath: str) -> Dict[str, Any]:
    """
    Analisa um arquivo de log de chamada e gera um relatório.
    """
    call_id = os.path.basename(filepath).replace('.log', '')
    events = load_log_file(filepath)
    
    if not events:
        return {
            "call_id": call_id,
            "error": "Arquivo de log vazio ou formato inválido"
        }
    
    transcription_stats = analyze_transcription_times(events)
    synthesis_stats = analyze_synthesis_times(events)
    ai_processing_stats = analyze_ai_processing_times(events)
    vad_stats = analyze_vad_performance(events)
    call_duration = analyze_call_durations(events)
    errors = analyze_errors(events)
    
    return {
        "call_id": call_id,
        "call_duration_ms": call_duration,
        "transcription_stats": transcription_stats,
        "synthesis_stats": synthesis_stats,
        "ai_processing_stats": ai_processing_stats,
        "vad_stats": vad_stats,
        "errors": errors,
        "event_count": len(events)
    }

def print_stats(title: str, stats: Dict[str, float], indent=0):
    """
    Imprime estatísticas formatadas.
    """
    indentation = " " * indent
    print(f"{indentation}{title}:")
    for key, value in stats.items():
        print(f"{indentation}  {key}: {value:.2f}ms")

def print_report(report: Dict[str, Any]):
    """
    Imprime um relatório formatado.
    """
    print(f"\n==== RELATÓRIO DE CHAMADA: {report['call_id']} ====")
    print(f"Duração total: {report['call_duration_ms']:.2f}ms ({report['call_duration_ms']/1000:.2f}s)")
    print(f"Total de eventos: {report['event_count']}")
    
    print("\n--- TEMPOS DE TRANSCRIÇÃO ---")
    print_stats("Todos", report['transcription_stats']['all'], 2)
    print_stats("Visitante", report['transcription_stats']['visitor'], 2)
    print_stats("Morador", report['transcription_stats']['resident'], 2)
    
    print("\n--- TEMPOS DE SÍNTESE ---")
    print_stats("Todos", report['synthesis_stats']['all'], 2)
    print_stats("Visitante", report['synthesis_stats']['visitor'], 2)
    print_stats("Morador", report['synthesis_stats']['resident'], 2)
    
    print("\n--- TEMPOS DE PROCESSAMENTO IA ---")
    print_stats("Total", report['ai_processing_stats']['total'], 2)
    
    print("\n  Extração de intenção:")
    print_stats("Tipo de intenção", report['ai_processing_stats']['intent_extraction']['intent_type'], 4)
    print_stats("Nome do interlocutor", report['ai_processing_stats']['intent_extraction']['interlocutor_name'], 4)
    print_stats("Apartamento e morador", report['ai_processing_stats']['intent_extraction']['apartment_and_resident'], 4)
    
    print_stats("Validação fuzzy", report['ai_processing_stats']['fuzzy_validation'], 2)
    
    print("\n--- DETECÇÃO DE VOZ ---")
    print_stats("Duração da fala", report['vad_stats']['speech_durations'], 2)
    print_stats("Duração do silêncio", report['vad_stats']['silence_durations'], 2)
    
    if report['errors']:
        print("\n--- ERROS DETECTADOS ---")
        for i, error in enumerate(report['errors']):
            print(f"  {i+1}. {error['error_type']}: {error['message']}")
            if error['details']:
                for k, v in error['details'].items():
                    print(f"     {k}: {v}")

def main():
    parser = argparse.ArgumentParser(description='Analisador de logs de chamadas')
    parser.add_argument('--call_id', help='ID específico da chamada para analisar')
    parser.add_argument('--all', action='store_true', help='Analisar todos os logs')
    parser.add_argument('--summary', action='store_true', help='Mostrar apenas resumo agregado')
    parser.add_argument('--output', help='Arquivo para salvar o relatório em JSON')
    args = parser.parse_args()
    
    logs_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'logs')
    
    if args.call_id:
        log_file = os.path.join(logs_dir, f"{args.call_id}.log")
        if not os.path.exists(log_file):
            print(f"Arquivo de log não encontrado: {log_file}")
            return
        
        report = analyze_log_file(log_file)
        print_report(report)
        
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, default=str)
    
    elif args.all or args.summary:
        log_files = glob.glob(os.path.join(logs_dir, "*.log"))
        
        if not log_files:
            print("Nenhum arquivo de log encontrado.")
            return
        
        all_reports = []
        for log_file in log_files:
            report = analyze_log_file(log_file)
            all_reports.append(report)
            
            if args.all and not args.summary:
                print_report(report)
        
        if args.summary:
            # Agregar estatísticas de todos os relatórios
            transcription_times = []
            synthesis_times = []
            ai_processing_times = []
            call_durations = []
            error_count = 0
            
            for report in all_reports:
                # Coletar tempos de transcrição
                for time_list in [report['transcription_stats']['visitor'], report['transcription_stats']['resident']]:
                    for key in ['avg', 'max']:
                        if time_list.get(key):
                            transcription_times.append(time_list[key])
                
                # Coletar tempos de síntese
                for time_list in [report['synthesis_stats']['visitor'], report['synthesis_stats']['resident']]:
                    for key in ['avg', 'max']:
                        if time_list.get(key):
                            synthesis_times.append(time_list[key])
                
                # Coletar tempos de processamento de IA
                if report['ai_processing_stats']['total'].get('avg'):
                    ai_processing_times.append(report['ai_processing_stats']['total']['avg'])
                
                # Coletar duração da chamada
                if report['call_duration_ms']:
                    call_durations.append(report['call_duration_ms'])
                
                # Contar erros
                error_count += len(report['errors'])
            
            print("\n==== RESUMO AGREGADO DE TODAS AS CHAMADAS ====")
            print(f"Total de chamadas analisadas: {len(all_reports)}")
            print(f"Total de erros encontrados: {error_count}")
            
            print("\n--- MÉDIAS GERAIS ---")
            print(f"Duração média das chamadas: {statistics.mean(call_durations)/1000:.2f}s")
            print(f"Tempo médio de transcrição: {statistics.mean(transcription_times):.2f}ms")
            print(f"Tempo médio de síntese: {statistics.mean(synthesis_times):.2f}ms")
            print(f"Tempo médio de processamento de IA: {statistics.mean(ai_processing_times):.2f}ms")
            
            print("\n--- MÁXIMOS GERAIS ---")
            print(f"Duração máxima de chamada: {max(call_durations)/1000:.2f}s")
            print(f"Tempo máximo de transcrição: {max(transcription_times):.2f}ms")
            print(f"Tempo máximo de síntese: {max(synthesis_times):.2f}ms")
            print(f"Tempo máximo de processamento de IA: {max(ai_processing_times):.2f}ms")
        
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(all_reports, f, indent=2, default=str)
    
    else:
        parser.print_help()

if __name__ == "__main__":
    main()

utils/call_logger.py:
import logging
import os
import time
from datetime import datetime
from typing import Dict, Optional, Any, Union
import json

class CallLogger:
    """
    Logger especializado para registrar detalhes de uma chamada específica.
    Cria um arquivo de log único para cada UUID de chamada com timestamps precisos
    para cada etapa do processo.
    """
    
    def __init__(self, call_id: str):
        self.call_id = call_id
        self.start_time = time.time()
        self.log_file = os.path.join('logs', f"{call_id}.log")
        
        # Configurar logger específico para esta chamada
        self.logger = logging.getLogger(f"call.{call_id}")
        
        # Remove handlers existentes para evitar duplicação se o logger já existir
        if self.logger.handlers:
            for handler in self.logger.handlers:
                self.logger.removeHandler(handler)
        
        # Definir nível de logging
        self.logger.setLevel(logging.DEBUG)
        
        # Criar file handler
        os.makedirs(os.path.dirname(self.log_file), exist_ok=True)
        file_handler = logging.FileHandler(self.log_file)
        
        # Definir formato
        formatter = logging.Formatter(
            '%(asctime)s.%(msecs)03d | %(levelname)s | %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        
        # Adicionar handler ao logger
        self.logger.addHandler(file_handler)
        
        # Registrar início da chamada
        self.log_event("CALL_STARTED", {
            "timestamp": datetime.now().isoformat()
        })
    
    def log_event(self, event_type: str, data: Dict[str, Any]) -> None:
        """
        Registra um evento com seu timestamp e dados adicionais.
        
        Args:
            event_type: Tipo do evento (ex: SPEECH_DETECTED, TRANSCRIPTION_COMPLETE)
            data: Dicionário com informações adicionais do evento
        """
        # Adicionar timestamp se não fornecido
        if "timestamp" not in data:
            data["timestamp"] = datetime.now().isoformat()
        
        # Adicionar tempo decorrido desde o início da chamada
        elapsed = time.time() - self.start_time
        data["elapsed_seconds"] = round(elapsed, 3)
        
        # Formatar mensagem para o log
        message = f"{event_type} | {json.dumps(data)}"
        self.logger.info(message)
    
    def log_speech_detected(self, is_visitor: bool = True) -> None:
        """Registra quando voz é detectada."""
        self.log_event("SPEECH_DETECTED", {
            "source": "visitor" if is_visitor else "resident"
        })
    
    def log_speech_ended(self, duration_ms: float, is_visitor: bool = True) -> None:
        """Registra quando a fala termina."""
        self.log_event("SPEECH_ENDED", {
            "source": "visitor" if is_visitor else "resident",
            "duration_ms": duration_ms
        })
    
    def log_transcription_start(self, audio_size: int, is_visitor: bool = True) -> None:
        """Registra início da transcrição."""
        self.log_event("TRANSCRIPTION_START", {
            "source": "visitor" if is_visitor else "resident",
            "audio_size_bytes": audio_size
        })
    
    def log_transcription_complete(self, text: str, duration_ms: float, is_visitor: bool = True) -> None:
        """Registra conclusão da transcrição."""
        self.log_event("TRANSCRIPTION_COMPLETE", {
            "source": "visitor" if is_visitor else "resident",
            "text": text,
            "duration_ms": duration_ms
        })
    
    def log_ai_processing_start(self, text: str) -> None:
        """Registra início do processamento pela IA."""
        self.log_event("AI_PROCESSING_START", {
            "input_text": text
        })
    
    def log_ai_processing_complete(self, response: Dict[str, Any], duration_ms: float) -> None:
        """Registra conclusão do processamento pela IA."""
        self.log_event("AI_PROCESSING_COMPLETE", {
            "response": response,
            "duration_ms": duration_ms
        })
    
    def log_synthesis_start(self, text: str, is_visitor: bool = True) -> None:
        """Registra início da síntese de voz."""
        self.log_event("SYNTHESIS_START", {
            "target": "visitor" if is_visitor else "resident",
            "text": text
        })
    
    def log_synthesis_complete(self, audio_size: int, duration_ms: float, is_visitor: bool = True) -> None:
        """Registra conclusão da síntese de voz."""
        self.log_event("SYNTHESIS_COMPLETE", {
            "target": "visitor" if is_visitor else "resident",
            "audio_size_bytes": audio_size,
            "duration_ms": duration_ms
        })
    
    def log_state_change(self, old_state: str, new_state: str) -> None:
        """Registra mudança de estado no fluxo de conversa."""
        self.log_event("STATE_CHANGE", {
            "from": old_state,
            "to": new_state
        })
    
    def log_silence_detected(self, duration_ms: float, is_visitor: bool = True) -> None:
        """Registra detecção de silêncio."""
        self.log_event("SILENCE_DETECTED", {
            "source": "visitor" if is_visitor else "resident",
            "duration_ms": duration_ms
        })
    
    def log_error(self, error_type: str, message: str, details: Optional[Dict[str, Any]] = None) -> None:
        """Registra ocorrência de erro."""
        data = {
            "error_type": error_type,
            "message": message
        }
        if details:
            data["details"] = details
        
        self.log_event("ERROR", data)
        self.logger.error(f"{error_type}: {message}")
    
    def log_call_ended(self, reason: str, duration_ms: Optional[float] = None) -> None:
        """Registra término da chamada."""
        if duration_ms is None:
            duration_ms = (time.time() - self.start_time) * 1000
            
        self.log_event("CALL_ENDED", {
            "reason": reason,
            "total_duration_ms": duration_ms
        })
        
        # Fechar todos os handlers
        for handler in self.logger.handlers:
            handler.close()
            self.logger.removeHandler(handler)


# Singleton para gerenciar os loggers de chamadas
class CallLoggerManager:
    _loggers: Dict[str, CallLogger] = {}
    
    @classmethod
    def get_logger(cls, call_id: str) -> CallLogger:
        """Obtém ou cria um logger para o ID de chamada especificado."""
        if call_id not in cls._loggers:
            cls._loggers[call_id] = CallLogger(call_id)
        return cls._loggers[call_id]
    
    @classmethod
    def remove_logger(cls, call_id: str) -> None:
        """Remove um logger após o término da chamada."""
        if call_id in cls._loggers:
            del cls._loggers[call_id]

utils/__init__.py:


utils/README.md:
# Sistema de Logs para Análise de Desempenho

Este sistema de logs foi projetado para monitorar e analisar o desempenho das chamadas no projeto AudioSocket-Simple. O sistema registra detalhadamente cada etapa do processamento de chamadas, permitindo identificar gargalos e problemas de performance.

## Estrutura

O sistema consiste em:

1. **CallLogger**: Classe que registra eventos específicos de uma chamada em um arquivo log único (um arquivo por chamada).
2. **CallLoggerManager**: Gerenciador singleton que mantém instâncias de loggers para cada chamada ativa.
3. **log_analyzer.py**: Script para analisar os arquivos de log e gerar relatórios.

## Funcionamento

Cada chamada telefônica gera um arquivo de log no formato `{uuid_chamada}.log` contendo entradas JSON estruturadas com:

- Timestamp preciso de cada evento
- Tempo decorrido desde o início da chamada
- Tipo de evento (ex: SPEECH_DETECTED, TRANSCRIPTION_COMPLETE, etc.)
- Dados específicos do evento (duração, texto transcrito, etc.)

## Tipos de Eventos Registrados

O sistema registra eventos em todas as fases de uma chamada:

### Processamento de Áudio
- Detecção de fala (`SPEECH_DETECTED`)
- Término de fala (`SPEECH_ENDED`) 
- Detecção de silêncio (`SILENCE_DETECTED`)

### Transcrição
- Início da transcrição (`TRANSCRIPTION_START`)
- Conclusão da transcrição (`TRANSCRIPTION_COMPLETE`)

### Processamento de IA
- Início do processamento (`AI_PROCESSING_START`)
- Extração de intenções (`INTENT_EXTRACTION_START`, `INTENT_EXTRACTION_COMPLETE`)
- Validação fuzzy (`FUZZY_VALIDATION_START`, `FUZZY_VALIDATION_COMPLETE`)
- Conclusão do processamento (`AI_PROCESSING_COMPLETE`)

### Síntese de Fala
- Início da síntese (`SYNTHESIS_START`)
- Conclusão da síntese (`SYNTHESIS_COMPLETE`)

### Eventos de Chamada
- Configuração da chamada (`CALL_SETUP`)
- Saudação (`GREETING`)
- Mudança de estado (`STATE_CHANGE`)
- Comunicação com morador (`CALL_MORADOR`, `MORADOR_CONNECTED`)
- Término da chamada (`CALL_ENDED`)

### Erros
- Erros ocorridos durante a chamada (`ERROR`)

## Análise de Logs

O script `log_analyzer.py` oferece:

1. **Análise de uma única chamada**: 
   ```
   python utils/log_analyzer.py --call_id UUID_DA_CHAMADA
   ```

2. **Análise de todas as chamadas**: 
   ```
   python utils/log_analyzer.py --all
   ```

3. **Resumo agregado**:
   ```
   python utils/log_analyzer.py --all --summary
   ```

4. **Exportação para JSON**:
   ```
   python utils/log_analyzer.py --all --output relatorio.json
   ```

## Identificando Gargalos

Os relatórios produzidos pelo analisador ajudam a identificar diversos problemas:

1. **Tempos de Transcrição**: Valores altos podem indicar problemas com o serviço de transcrição ou qualidade do áudio.

2. **Tempos de Processamento da IA**: Valores elevados em etapas específicas (ex: extração de intenção) podem apontar necessidade de otimização dos modelos.

3. **Tempos de Síntese**: Atrasos na geração de áudio sintético que podem degradar a experiência.

4. **Detecção de VAD**: Problemas no reconhecimento de início e fim de falas.

5. **Erros**: Registro completo de falhas ocorridas durante as chamadas.

## Exemplo de Uso

Para usar este sistema em seu código, simplesmente obtenha um logger para a chamada atual:

```python
from utils.call_logger import CallLoggerManager

# No início de uma chamada
call_id = "uuid_da_chamada"
call_logger = CallLoggerManager.get_logger(call_id)

# Durante a chamada, registre eventos
call_logger.log_speech_detected()
call_logger.log_transcription_start(audio_data_size)
call_logger.log_transcription_complete(transcribed_text, transcription_time)
call_logger.log_ai_processing_start(transcribed_text)
call_logger.log_ai_processing_complete(response, processing_time)
call_logger.log_synthesis_start(response_text)
call_logger.log_synthesis_complete(audio_size, synthesis_time)

# Registrar eventos personalizados
call_logger.log_event("MY_CUSTOM_EVENT", {
    "some_key": "some_value",
    "another_key": 123
})

# No final da chamada
call_logger.log_call_ended("normal_disconnection")
CallLoggerManager.remove_logger(call_id)  # Liberar recursos
```

docs/resume.md:
# Arquitetura do Projeto AudioSocket-Simple

## Visão Geral

O AudioSocket-Simple é um sistema de atendimento por IA para condomínios que utiliza o protocolo AudioSocket do Asterisk para gerenciar chamadas VoIP. O sistema permite automatizar o atendimento a visitantes e entregas, conectando-os com os moradores através de um assistente virtual inteligente.

## Componentes Principais

### 1. Servidores AudioSocket

O sistema mantém dois servidores AudioSocket paralelos:
- **Servidor Visitante (porta 8080)**: Atende chamadas provenientes de visitantes no portão.
- **Servidor Morador (porta 8081)**: Atende chamadas para moradores autorizados.

### 2. Gerenciamento de Sessões

- **SessionManager**: Armazena e gerencia o estado das conversas entre visitantes e moradores.
- **SessionData**: Mantém filas de mensagens independentes para visitantes e moradores, além do histórico da conversa.
- **FlowState**: Define o estado do fluxo da conversa (COLETANDO_DADOS, VALIDADO, CHAMANDO_MORADOR, etc.).

### 3. Processamento de Áudio

- **VAD (Voice Activity Detection)**: Detecta quando o usuário começa e termina de falar.
- **Azure Speech Services**: Realiza a transcrição de fala para texto e síntese de texto para fala.

### 4. Integração com IA

- **CrewAI**: Framework utilizado para coordenar agentes especializados na extração de intenções e dados.
- **Agents**: Agentes especializados para diferentes tarefas de entendimento contextual.
- **Tasks**: Tarefas específicas para extrair informações como intenção, nome do visitante, apartamento e morador.

### 5. Comunicação AMQP

- **RabbitMQ**: Utilizado para enviar solicitações de clicktocall para conectar com moradores.

## Fluxo de Uma Chamada Completa

1. **Inicialização**:
   - O sistema inicia dois servidores (visitante e morador) para receber conexões.

2. **Atendimento ao Visitante**:
   - Visitante realiza uma chamada para o sistema.
   - O sistema inicia uma nova sessão e responde com mensagem de saudação.
   - Duas tarefas assíncronas são iniciadas: uma para receber áudio e outra para enviar respostas.

3. **Extração de Intenções**:
   - O sistema usa VAD para detectar quando o visitante está falando.
   - Quando o visitante termina de falar, o áudio é transcrito pelo Azure Speech.
   - A transcrição é enviada ao `SessionManager.process_visitor_text()`.
   - O `ConversationFlow` processa a mensagem através de `on_visitor_message()`.

4. **Pipeline de Compreensão**:
   - A mensagem é processada pelo `process_user_message_with_coordinator()`.
   - A IA extrai informações em etapas sequenciais:
     1. Identificação do tipo de intenção (entrega/visita)
     2. Extração do nome do visitante
     3. Extração do número do apartamento e nome do morador

5. **Validação dos Dados**:
   - Após coletar todos os dados, o sistema valida as informações usando `validar_intent_com_fuzzy()`.
   - Verifica se o apartamento existe e se o morador corresponde aos registros.

6. **Contato com o Morador**:
   - Quando os dados são validados, o estado muda para `CHAMANDO_MORADOR`.
   - O sistema envia uma mensagem AMQP via RabbitMQ para iniciar uma chamada com o morador.
   - Inicia um monitor assíncrono para verificar se o morador atendeu dentro de 10 segundos.
   - Se não atender, tenta novamente (até 2 tentativas).

7. **Interação com o Morador**:
   - Quando o morador atende, o estado muda para `ESPERANDO_MORADOR`.
   - O sistema informa o morador sobre o visitante aguardando.
   - O morador responde "SIM" ou "NÃO" para autorizar ou negar a entrada.

8. **Conclusão**:
   - Baseado na resposta do morador, o sistema informa o visitante.
   - O estado muda para `FINALIZADO`.
   - A sessão é encerrada e removida do gerenciador.

## Estados da Máquina de Fluxo de Conversa

### Estados da StateMachine
- **STANDBY**: Estado inicial, aguardando nova chamada
- **USER_TURN**: Turno do usuário (sistema está ouvindo)
- **WAITING**: Estado intermediário de processamento
- **IA_TURN**: Turno da IA (sistema está respondendo)

### Estados do ConversationFlow
- **COLETANDO_DADOS**: Fase de extração de informações do visitante
- **VALIDADO**: Dados foram validados com sucesso
- **CHAMANDO_MORADOR**: Sistema está tentando contactar o morador
- **ESPERANDO_MORADOR**: Morador atendeu, aguardando resposta
- **FINALIZADO**: Fluxo concluído, chamada encerrada

## Modelo de Intenções

O sistema extrai e processa intenções estruturadas:
- **intent_type**: Tipo de intenção (visita/entrega)
- **interlocutor_name**: Nome do visitante
- **apartment_number**: Número do apartamento
- **resident_name**: Nome do morador

## Pontos Fortes da Arquitetura

1. **Design Assíncrono**: Utiliza `asyncio` para operações não bloqueantes e concorrentes.
2. **Separação de Responsabilidades**: Componentes bem definidos com funções específicas.
3. **Máquina de Estados Robusta**: Transições claras entre estados da conversa.
4. **Pipeline de IA Modular**: Extração de informações em etapas segregadas e especializadas.
5. **Filas de Mensagens**: Comunicação eficiente entre componentes através de filas assíncronas.
6. **Integração com Sistemas Externos**: Azure Speech Services e RabbitMQ.

## Possíveis Melhorias

1. **Tratamento de Erros**: Implementar estratégias mais robustas para falhas na transcrição ou comunicação.
2. **Testes Automatizados**: Adicionar testes unitários e de integração.
3. **Configuração Externalizada**: Mover valores hardcoded para arquivos de configuração.
4. **Logging Estruturado**: Melhorar o sistema de logs para facilitar depuração.
5. **Métricas e Monitoramento**: Adicionar telemetria para monitorar desempenho e identificar gargalos.
6. **Cache**: Implementar cache para respostas de IA frequentes.
7. **Autenticação e Segurança**: Adicionar camadas de segurança para o protocolo AudioSocket.

docs/README.md:
# AudioSocket Simple

Aplicação simplificada para atendimento por IA em condomínios utilizando o protocolo AudioSocket do Asterisk.

## Descrição

Esta aplicação é responsável por gerenciar chamadas VoIP através do protocolo AudioSocket, realizando:

1. Detecção de voz usando VAD (Voice Activity Detection)
2. Transcrição do áudio usando Azure Speech Services
3. Processamento de intenções via API de IA
4. Síntese de voz para respostas
5. Gerenciamento de turnos de conversa entre usuário e IA

## Funcionalidades principais

- Socket TCP para comunicação com o Asterisk via protocolo AudioSocket
- Máquina de estados simplificada com 4 estados (STANDBY, USER_TURN, WAITING, IA_TURN)
- Gerenciamento de IDs de conversa para manter o contexto entre mensagens
- Mensagem de saudação automática configurável
- Detecção de voz e silêncio usando webrtcvad
- Transcrição de áudio através do Azure Speech Services
- Comunicação com API de IA para processar mensagens do usuário
- Síntese de voz usando Azure Speech Services
- Interface web simples para debug e monitoramento

## Requisitos

- Python 3.8+
- Biblioteca webrtcvad para detecção de voz
- Azure Speech Services para transcrição e síntese de voz
- API de IA para processamento de mensagens

## Configuração

1. Crie um arquivo `.env` com as seguintes variáveis de ambiente:
   ```
   AZURE_SPEECH_KEY=sua_chave_do_azure
   AZURE_SPEECH_REGION=sua_regiao_do_azure
   SILENCE_THRESHOLD_SECONDS=2.0
   AI_API_URL=http://localhost:8000/messages
   ```

2. Instale as dependências:
   ```
   pip install -r requirements.txt
   ```

3. Personalize a mensagem de saudação no arquivo `config.json`:
   ```json
   {
     "greeting": {
       "message": "Condomínio Apoena, em que posso ajudar?",
       "voice": "pt-BR-AntonioNeural",
       "delay_seconds": 2
     },
     ...
   }
   ```

## Execução

### Servidor principal
Inicie o servidor principal que lida com a chamada e inclui a interface web de debug:
```
python main.py
```

O servidor AudioSocket irá escutar em 127.0.0.1:8080 e a interface web de debug estará disponível em http://127.0.0.1:8081.

### Cliente de teste com microfone
Para testar o sistema com seu microfone local:
```
python microfone_client.py
```

Este cliente captura áudio do microfone do seu computador e o envia para o servidor AudioSocket, permitindo testar toda a funcionalidade sem precisar do Asterisk.

Opções disponíveis:
```
python microfone_client.py --host 127.0.0.1 --port 8080
```

## Fluxo de conversação

1. **Estado STANDBY**: 
   - Sistema aguarda uma conexão
   - Ao receber uma conexão, registra o ID da chamada
   - Após um breve delay, envia a mensagem de saudação
   
2. **Estado USER_TURN**:
   - Sistema ativa após a saudação
   - Detecta quando o usuário começa a falar
   - Captura o áudio até identificar silêncio
   - Transcreve o áudio usando Azure Speech
   
3. **Estado WAITING**:
   - Processa o texto transcrito
   - Envia para a API de IA
   
4. **Estado IA_TURN**:
   - Recebe a resposta da IA
   - Sintetiza a fala usando Azure Speech
   - Envia o áudio de resposta
   - Retorna para USER_TURN ou STANDBY dependendo da resposta da IA

## Interface de Debug

A interface web de debug mostra:
- Estado atual da chamada
- ID da conversa ativa
- Histórico de transcrições (usuário, IA e sistema)

A página atualiza automaticamente a cada 2 segundos para mostrar o estado atual.

## API de IA

A aplicação se comunica com uma API de IA pela URL `http://localhost:8000/messages` que deve retornar uma resposta no formato:

```json
{
    "content": {
        "mensagem": "Texto da resposta da IA",
        "dados": {
            "intent_type": "tipo_intencao",
            "outros_dados": "valores_relevantes"
        },
        "valid_for_action": false
    },
    "timestamp": "2025-04-15T19:17:59.052067",
    "set_call_status": "USER_TURN"
}
```

O campo `set_call_status` pode ter os valores: "USER_TURN", "WAITING", "IA_TURN" ou "STANDBY" para controlar o fluxo da conversa.

ai/state_manager.py:
import redis
import json

r = redis.Redis(host='localhost', port=6379, decode_responses=True)

def get_user_state(id: str):
    data = r.get(id)
    return json.loads(data) if data else {"intent": {}, "history": []}

def update_user_state(user_id: str, intent=None, message=None):
    state = get_user_state(user_id)
    if intent:
        state["intent"].update(intent)
    if message:
        state["history"].append(message)
    r.set(user_id, json.dumps(state))

def clear_user_state(user_id: str):
    r.delete(user_id)


ai/tasks.py:
from crewai import Task
from ai.agents import (create_conversation_coordinator_agent, create_conversation_monitor_agent,
                       identificator_person_agent, identificator_intent_agent, identificator_resident_apartment_agent)


def create_conversation_coordinator_task(user_message: str, conversation_history: str, intent: dict) -> Task:
    agent = create_conversation_coordinator_agent()
    monitor = create_conversation_monitor_agent()
    print(conversation_history)
    return Task(
        description=f"""
        Você é um concierge virtual em uma conversa com alguém no portão do condomínio.

        Histórico da conversa:
        {conversation_history}

        Mensagem nova:
        "{user_message}"

        Intenção acumulada até agora:
        {intent}

        Seu trabalho:
        - Verificar se todos os campos estão preenchidos:
          • intent_type
          • interlocutor_name
          • apartment_number
          • resident_name
        - Se faltar algo, pergunte o que falta.
        - Se estiver completo, apenas confirme.

        Regras:
        - NÃO repita o que já foi dito.
        - NÃO reinicie a conversa.
        - Não peça dados que já estão no intent.
        """,
        # expected_output="""
        # Mensagem para o usuário ou confirmação final.
        # Confirme a ação de forma educada, objetiva e breve.
        # Exemplos de formato desejado:
        # - "Entrega confirmada para Fulano no xxxx. Notificarei o morador."
        # - "Entendido, vou avisar Cicrano no apartamento bla bla bla."
        # Evite repetições desnecessárias, não deseje bom dia ou acrescente floreios.
        # """,
        expected_output=""""
        Responda em formato JSON com os seguintes campos:
        - mensagem: mensagem de resposta clara e objetiva para o usuário, podendo ser a confirmação final. 
        Confirme a ação de forma educada, objetiva e breve. Ex, "Entrega confirmada para Fulano no xxxx. Notificarei o 
        morador"., ou ainda, "Entendido, vou avisar Cicrano no apartamento bla bla bla."
        - dados: objeto com os campos intent_type, interlocutor_name, apartment_number e resident_name.
        
        Exemplo:
        {
          "mensagem": "Entrega confirmada para Fulano do XXXX.",
          "dados": {
            "intent_type": "entrega",
            "interlocutor_name": "João",
            "apartment_number": "XXXX",
            "resident_name": "Fulano"
          }
        }
        O campo message é sempre obrigatório, pois você sempre deve ter uma resposta, mesmo que seja uma pergunta para 
        quem está sendo atendido. Se não puder identificar os campos de dados, retorne as chaves com valores vazios. 
        Não use floreios, não repita informações já ditas, apenas informe ou confirme a ação.
        O campo intent_type dentro de dados deve ser preenchido com entrega, visita ou desconhecido, conforme o que 
        você identificar.
        
        Alguns exemplos de campos faltando e possíveis respostas:
        {
          "mensagem": "Informe o que deseja",
          "dados": {
            "intent_type": "",
            "interlocutor_name": "",
            "apartment_number": "",
            "resident_name": ""
          }
        }
        
        {
          "mensagem": "Por favor, me informe o nome do visitante, o apartamento e o nome do morador que autorizou",
          "dados": {
            "intent_type": "visita",
            "interlocutor_name": "",
            "apartment_number": "",
            "resident_name": ""
          }
        } 
        
        {
          "mensagem": "Por favor, me informe o seu nome, o apartamento e o nome do morador que vai receber a entrega",
          "dados": {
            "intent_type": "entrega",
            "interlocutor_name": "",
            "apartment_number": "",
            "resident_name": ""
          }
        }                 
                
        {
          "mensagem": "Por favor, me informe o nome do morador.",
          "dados": {
            "intent_type": "entrega",
            "interlocutor_name": "Carlos",
            "apartment_number": "301",
            "resident_name": ""
          }
        }
        
        {
          "mensagem": "Por favor, me informe sua intenção",
          "dados": {
            "intent_type": "",
            "interlocutor_name": "Carlos",
            "apartment_number": "301",
            "resident_name": "Fulano"
          }
        }
        
        {
          "mensagem": "Podes informar o seu nome?",
          "dados": {
            "intent_type": "visita",
            "interlocutor_name": "",
            "apartment_number": "301",
            "resident_name": "Fulano"
          }
        }      
        
        {
          "mensagem": "Podes informar o número do apartamento?",
          "dados": {
            "intent_type": "visita",
            "interlocutor_name": "Cicrano",
            "apartment_number": "",
            "resident_name": "Fulano"
          }
        }              
        
        
        """,
        agent=agent
    )


def conversation_extractor_name_task(user_message: str, conversation_history: str, intent: dict) -> Task:
    agent = identificator_person_agent()
    print(conversation_history)
    return Task(
        description=f"""
        Você é o concierge inicial virtual do condomínio em uma conversa com alguém no portão do condomínio.

        Histórico da conversa:
        {conversation_history}

        Mensagem nova:
        "{user_message}"

        Intenção acumulada até agora:
        {intent}

        Seu trabalho:
        - Verificar se o campo interlocutor_name está preenchido:
          • interlocutor_name
        - Se não souber o nome da pessoa, pergunte
        - Se estiver completo, com um nome legível e aceitável, apenas confirme.

        Regras:
        - NÃO repita o que já foi dito.
        - NÃO reinicie a conversa.
        - Não peça dados que já estão no identificados.
        """,
        expected_output=""""
        Responda em formato JSON onde o campo interlocutor_name deve estar preenchido com o nome do visitante. 
        O campo de intent_type também deve estar preenchido pois já perguntamos isso ao interlocutor. Os outros
        campos (apartment_number e resident_name) dentro de dados serão preenchidos pelos outros concierges. 
        Exemplo de mensagem quando ainda não foi identificado o nome:
        {
          "mensagem": "Por favor, me informe o seu nome",
          "dados": {
            "intent_type": "",
            "interlocutor_name": "",
            "apartment_number": "",
            "resident_name": ""
          }
        }
        
        Exemplo de mensagem quando foi identificado o nome:
        {
          "mensagem": "Obrigado Fulano, aguarde um instante",
          "dados": {
            "intent_type": "",
            "interlocutor_name": "Fulano",
            "apartment_number": "",
            "resident_name": ""
          }
        }
        """,
        agent=agent
    )


def conversation_extractor_intent_task(user_message: str, conversation_history: str, intent: dict) -> Task:
    agent = identificator_intent_agent()
    print(conversation_history)
    return Task(
        description=f"""
        Você é o concierge virtual primário do condomínio em uma conversa com alguém no portão do condomínio.

        Histórico da conversa:
        {conversation_history}

        Mensagem nova:
        "{user_message}"

        Intenção acumulada até agora:
        {intent}

        Seu trabalho:
        - Verificar se o campo intent_type está preenchido:
          • intent_type
        - Se não souber a intenção da pessoa, pergunte.
        - Se estiver completo, com a intenção identificada entre entrega e visita, apenas confirme.

        Regras:
        - NÃO repita o que já foi dito.
        - NÃO reinicie a conversa.
        - Não peça dados que já estão no identificados.
        """,
        expected_output=""""
        Responda em formato JSON onde o campo intent_type deve estar preenchido com a intenção do visitante. Os outros
        campos dentro de dados serão preenchidos pelos outros concierges.
        Mesmo que o usuário diga outras informações, ignore informações como o apartamento e o nome do morador, 
        apenas retorne a intenção (intent_type).

        Exemplo de mensagem quando ainda não foi identificadoa a intenção:
        {
          "mensagem": "Por favor, me informe sua intenção, se visita ou entrega",
          "dados": {
            "intent_type": "",
            "interlocutor_name": "Fulano",
            "apartment_number": "",
            "resident_name": ""
          }
        }

        Exemplo de mensagem quando foi identificada a intenção:
        {
          "mensagem": "Obrigado Fulano, aguarde um instante",
          "dados": {
            "intent_type": "visita",
            "interlocutor_name": "Fulano",
            "apartment_number": "",
            "resident_name": ""
          }
        }
        """,
        agent=agent
    )


def conversation_extractor_resident_apartment_task(user_message: str, conversation_history: str, intent: dict) -> Task:
    agent = identificator_resident_apartment_agent()
    print(conversation_history)
    return Task(
        description=f"""
        Você é o concierge virtual terciário em uma conversa com alguém no portão do condomínio.

        Histórico da conversa:
        {conversation_history}

        Mensagem nova:
        "{user_message}"

        Intenção acumulada até agora:
        {intent}

        Seu trabalho:
        - Verificar se os campos apartment_number e resident_name estão preenchidos:
          • apartment_number
          • resident_name
        - Se não souber o apartamento ou o morador, pergunte
        - Se estiver completo, com o apartamento e o nome do morador, apenas confirme.

        Regras:
        - NÃO repita o que já foi dito.
        - NÃO reinicie a conversa.
        - Não peça dados que já estão no identificados.
        """,
        expected_output=""""
        Responda em formato JSON onde os campos apartment_number e resident_name devem estar preenchidos com o
        número do apartamento e nome do morador. Os outros campos serão preenchidos pelos outros concierges.

        Exemplo de mensagem quando ainda não foi identificado o apartamento ou o morador:
        {
          "mensagem": "Por favor, me informe sua para qual apartamento e o nome do morador",
          "dados": {
            "intent_type": "visita",
            "interlocutor_name": "Fulano",
            "apartment_number": "",
            "resident_name": ""
          }
        }

        Exemplo de mensagem quando foi identificado o apartamento e o morador:
        {
          "mensagem": "Obrigado Fulano, aguarde um instante",
          "dados": {
            "intent_type": "visita",
            "interlocutor_name": "Fulano",
            "apartment_number": "501",
            "resident_name": "Cicrano"
          }
        }
        """,
        agent=agent
    )


ai/tools.py:
from rapidfuzz import fuzz
import json
from pathlib import Path
from typing import Dict
from ai.models.intent import IntentData
from crewai.tools import tool

VALID_APT_PATH = Path("data/apartamentos.json")

@tool("SendMessageTool")
def identify_user_intent(message: str) -> str:
    """
    Extrai intenção do usuário com base na mensagem utilizando um modelo LLM.
    Retorna um JSON no formato esperado por UserIntent.
    """
    return message


# @tool("ValidarIntentComFuzzyTool")
def validar_intent_com_fuzzy(intent: Dict) -> Dict:
    """
    Verifica se a combinação apartment_number e resident_name da intent
    corresponde (mesmo que parcialmente) a um morador real.

    Retorna um dicionário:
    {
      "status": "válido" ou "inválido",
      "match_name": "Fulano de Tal",
      "voip_number": "1003031"
    }
    """
    try:
        apt = intent.get("apartment_number", "").strip().lower()  # 'apartment_number
        resident_informado = intent.get("resident_name", "").strip().lower()

        # Regras de pré-processamento para melhorar matches
        # Normalizar nomes comuns
        residentes_alternativos = {
            "daner": ["daniel", "daner", "dani", "danir", "taner"],
            "renata": ["renata", "renato"]
        }
        
        # Log para debug
        print(f"Validando: Apt={apt}, Morador={resident_informado}")

        if not apt or not resident_informado:
            return {
                "status": "inválido",
                "reason": "Faltando número do apartamento ou nome do morador"
            }

        try:
            with open(VALID_APT_PATH, "r", encoding="utf-8") as f:
                apartamentos = json.load(f)
        except Exception as e:
            print(f"Erro ao ler arquivo de apartamentos: {e}")
            # Resposta de fallback para não interromper o fluxo
            return {
                "status": "erro",
                "message": f"Erro ao ler dados: {str(e)}"
            }

        # Primeiro tenta match exato de apartamento
        apt_matches = [a for a in apartamentos if a["apartment_number"] == apt]
        if not apt_matches:
            print(f"Nenhum apartamento {apt} encontrado")
            # Tentativa com fuzzy no apartamento (se for um erro de digitação)
            best_apt_score = 0
            best_apt_match = None
            for apartamento in apartamentos:
                apt_score = fuzz.ratio(apt, apartamento["apartment_number"])
                if apt_score > best_apt_score and apt_score >= 85:
                    best_apt_score = apt_score
                    best_apt_match = apartamento
            
            if best_apt_match:
                print(f"Encontrado apartamento próximo: {best_apt_match['apartment_number']} (score={best_apt_score})")
                apt_matches = [best_apt_match]

        # Se não encontrar o apartamento, retorna inválido
        if not apt_matches:
            return {
                "status": "inválido",
                "reason": f"Apartamento {apt} não encontrado"
            }
            
        # Procura melhor match de residente nos apartamentos encontrados
        best_match = None
        best_score = 0
        best_apt = None
        
        for apartamento in apt_matches:
            for residente in apartamento["residents"]:
                nome_residente = residente.strip().lower()
                
                # Pontuações para diferentes algoritmos de match
                scores = [
                    fuzz.ratio(resident_informado, nome_residente),  # Match completo
                    fuzz.partial_ratio(resident_informado, nome_residente),  # Match parcial
                    fuzz.token_sort_ratio(resident_informado, nome_residente)  # Ignora ordem das palavras
                ]
                
                # Verificar também nomes alternativos comuns
                for nome_base, alternativas in residentes_alternativos.items():
                    if nome_base in nome_residente:
                        for alt in alternativas:
                            if alt in resident_informado:
                                scores.append(95)  # Adiciona alta pontuação para alternativas conhecidas
                
                # Usar o melhor score entre os algoritmos
                score = max(scores)
                print(f"Comparando '{resident_informado}' com '{nome_residente}': score={score}")
                
                if score > best_score:
                    best_score = score
                    best_match = residente
                    best_apt = apartamento

        # Umbral mais baixo para melhorar a taxa de aceitação
        if best_score >= 75:
            print(f"Match encontrado: {best_match} no apt {best_apt['apartment_number']} (score={best_score})")
            return {
                "status": "válido",
                "match_name": best_match,
                "voip_number": best_apt["voip_number"],
                "match_score": best_score,
                "apartment_number": best_apt["apartment_number"]
            }
        else:
            print(f"Melhor match encontrado: {best_match} (score={best_score}), mas abaixo do umbral")

        return {
            "status": "inválido",
            "reason": "Morador não encontrado neste apartamento",
            "best_match": best_match,
            "best_score": best_score
        }
    except Exception as e:
        print(f"Erro na validação fuzzy: {e}")
        return {
            "status": "erro",
            "message": str(e)
        }


ai/__init__.py:


ai/agents.py:
import os
from crewai import Agent

def identificator_person_agent() -> Agent:
    """
    Cria e retorna um agente responsável por conversar com o usuário,
    para identificar quem está falando.
    """
    return Agent(
        role="Primeiro Concierge Virtual do Condomínio",
        goal="Atender o usuário com empatia e eficiência, visando identificar quem esta falando",
        backstory="""
        Você é o primeiro concierge virtual treinado para conversar com pessoas no interfone da portaria de um condomínio.

        Seu trabalho é:
        - Solicitar a identificação da pessoa que está falando
        - Coletar :
          - Quem está no portão (interlocutor_name) (obrigatório)
          - Solicitar que a pessoa identifique-se para que o atendimento continue
          - Analise se o nome informado realmente é um nome aceitável, o usuário pode informar coisas como:
            - "Olá, tudo bem?" ou ainda
            - "Boa tarde", isso não é um nome válido
          - Você precisa interagir até que o nome seja obtido
        - Sua função não é identificar outras informações, apenas obter o nome e a identificação de quem está falando.
        """,
        verbose=False,
        allow_delegation=False,
    )

def identificator_intent_agent() -> Agent:
    """
    Cria e retorna um agente responsável por conversar com o usuário,
    para identificar qual a intenção do usuário.
    """
    return Agent(
        role="Segundo Concierge Virtual do Condomínio",
        goal="Atender o usuário com empatia e eficiência, visando identificar qual a intenção do usuário",
        backstory="""
        Você é o segundo concierge virtual treinado para conversar com pessoas no interfone da portaria de um condomínio.

        Seu trabalho é:
        - Solicitar a qual a intenção da pessoa que está falando
        - Coletar :
          - Qual a intenção da pessoa (intent_type)
          - Por hora, aceitamos apenas duas intenções, entrega ou visita. Precisamos identificar se a intenção 
          é uma dessas duas.
        - Sua função não é identificar outras informações, apenas obter a intenção de quem está falando.
        """,
        verbose=False,
        allow_delegation=False,
    )

def identificator_resident_apartment_agent() -> Agent:
    """
    Cria e retorna um agente responsável por conversar com o usuário,
    para identificar quam o nome do morador e apartamento.
    """
    return Agent(
        role="Terceiro Concierge Virtual do Condomínio",
        goal="Atender o usuário com empatia e eficiência, visando identificar qual a apartamento do morador e o nome "
             "do morador",
        backstory="""
        Você é o terceiro concierge virtual treinado para conversar com pessoas no interfone da portaria de um condomínio.

        Seu trabalho é:
        - Solicitar a qual a nome do morador e qual o apartamento
        - Coletar :
          - Qual o nome do morador (resident_name)
          - Qual o apartamento (apartment_number)
        - Sua função não é identificar outras informações, apenas obter o nome do morador e o apartamento.
        """,
        verbose=False,
        allow_delegation=False,
    )

def create_conversation_coordinator_agent() -> Agent:
    """
    Cria e retorna um agente responsável por conversar com o usuário,
    entender sua intenção e coletar todas as informações necessárias.
    """
    return Agent(
        role="Concierge Virtual do Condomínio",
        goal="Atender o usuário com empatia e eficiência, entendendo e completando sua solicitação",
        backstory="""
        Você é um concierge virtual treinado que conversa com pessoas no interfone da portaria de um condomínio.

        Seu trabalho é:
        - Entender se a pessoa deseja fazer uma entrega ou visita (obrigatório)
        - Coletar todas as informações necessárias:
          • Quem está no portão (interlocutor_name) (obrigatório)
          • Número do apartamento de destino (apartment_number) (obrigatório)
          • Nome do morador (resident_name) (obrigatório)
        - Confirmar quando tudo estiver preenchido
        - Jamais perguntar algo que o usuário já informou
        - Nunca delegar sua responsabilidade de entender a solicitação
        - Nunca confunda entrega com visita, se o morador diz que vai ou deseja ir em um apartamento, provável visita

        Quando tiver todas as informações, apenas finalize a conversa com uma resposta simpática e diga que irá notificar o morador.
        """,
        verbose=False,
        allow_delegation=False,
    )


def create_conversation_monitor_agent() -> Agent:
    """
    Cria e retorna um agente responsável por conversar com o usuário,
    entender sua intenção e coletar todas as informações necessárias.
    """
    return Agent(
        role="Gerente do Concierge Virtual do Condomínio",
        goal="Supervisionar o concierge virtual e garantir que ele vai extrair todos os dados que precisamos do usuário",
        backstory="""
        Você é um gerente senior e sua função é garantir que os etendentes da portaria remota (concierge virtual) 
        extraiam as informações corretas do usuário. Há relatos de que os atendentes estão chamando o morador, sem saber 
        qual a intenção ou sequer perguntar o nome de quem está falando ou se deseja uma visita ou entrega. 

        Seu trabalho é:
        - Identificar primeiro a pessoa que está falando com o concierge virtual e qual sua intenção
        - Somente pergunte o nome do morador e o apartamento se já houver identificado a interação e o nome do vistnate ou entregador
        - Fiscalizar o trabalho do concierge virtual
        - Garantir que ele vau coletar todas as informações necessárias:
          • Identificar a intenção do usuário (intent_type) obrigatório: se é visita ou entrega
          • Quem está no portão (interlocutor_name) (obrigatório)
          • Número do apartamento de destino (apartment_number) (obrigatório)
          • Nome do morador (resident_name) (obrigatório)
        - Nunca finalize a conversa se qualquer campo estiver vazio.
        - Se o nome do morador estiver vazio, você deve perguntar isso.

        Fiscalize as respostas antes de serem enviadas ao usuário garantindo tudo que foi solicitado.
        """,
        verbose=False,
        allow_delegation=False,
    )


ai/crew.py:
from crewai import Crew
import time

from ai.state_manager import get_user_state, update_user_state, clear_user_state
from ai.tasks import create_conversation_coordinator_task, conversation_extractor_name_task, \
    conversation_extractor_intent_task, conversation_extractor_resident_apartment_task
from ai.tools import validar_intent_com_fuzzy
from ai.utils.intent_extractor import extract_intent_from_response
from ai.models.intent import IntentData
import json
from utils.call_logger import CallLoggerManager

def process_user_message_with_coordinator(id: str, message: str) -> dict:
    # Obter logger para esta chamada
    call_logger = CallLoggerManager.get_logger(id)
    
    # Marcar início do processamento pela IA
    call_logger.log_ai_processing_start(message)
    total_start_time = time.time()
    
    state = get_user_state(id)
    history = "\n".join(state["history"])
    partial_intent = state["intent"]
    dados_estruturados = None

    # A partir do nome obtido, verifica a intenção do usuário
    if not state["intent"] or state["intent"]["intent_type"] == "":
        call_logger.log_event("INTENT_EXTRACTION_START", {
            "stage": "intent_type",
            "current_intent": str(partial_intent)
        })
        
        intent_start_time = time.time()
        task = conversation_extractor_intent_task(
            user_message=message,
            conversation_history=history,
            intent=partial_intent
        )
        crew = Crew(tasks=[task], verbose=True)
        result = str(crew.kickoff())
        intent_duration = (time.time() - intent_start_time) * 1000
        
        try:
            dados_estruturados = extract_intent_from_response(result)
            update_user_state(id, intent=dados_estruturados.get("dados"),
                              message=f"Usuário: {message}\nResposta LLM: {dados_estruturados.get('mensagem')}")
            
            call_logger.log_event("INTENT_EXTRACTION_COMPLETE", {
                "stage": "intent_type",
                "result": dados_estruturados["dados"]["intent_type"],
                "duration_ms": round(intent_duration, 2)
            })
        except Exception as e:
            update_user_state(id, message=f"Usuário: {message}")
            call_logger.log_error("INTENT_EXTRACTION_ERROR", 
                                str(e), 
                                {"stage": "intent_type"})
            
            # Criar um dados_estruturados default para evitar erros
            dados_estruturados = {
                "mensagem": "Desculpe, não consegui entender. Poderia repetir?",
                "dados": {"intent_type": "", "interlocutor_name": "", "apartment_number": "", "resident_name": ""},
                "valid_for_action": False
            }

        if dados_estruturados["dados"]["intent_type"] == "" or dados_estruturados["dados"]["intent_type"] == "desconhecido":
            ai_duration = (time.time() - total_start_time) * 1000
            call_logger.log_ai_processing_complete(dados_estruturados, ai_duration)
            return dados_estruturados

    state = get_user_state(id)
    history = "\n".join(state["history"])
    partial_intent = state["intent"]

    # Verifica se o nome foi obtido, caso contrário interage com o usuário para extrair essa informação
    if state["intent"] and state["intent"]["interlocutor_name"] == "":
        call_logger.log_event("INTENT_EXTRACTION_START", {
            "stage": "interlocutor_name",
            "current_intent": str(partial_intent)
        })
        
        name_start_time = time.time()
        task = conversation_extractor_name_task(
            user_message=message,
            conversation_history=history,
            intent=partial_intent
        )
        crew = Crew(tasks=[task], verbose=True)
        result = str(crew.kickoff())
        name_duration = (time.time() - name_start_time) * 1000
        
        try:
            dados_estruturados = extract_intent_from_response(result)
            update_user_state(id, intent=dados_estruturados.get("dados"),
                              message=f"Usuário: {message}\nResposta LLM: {dados_estruturados.get('mensagem')}")
            
            call_logger.log_event("INTENT_EXTRACTION_COMPLETE", {
                "stage": "interlocutor_name",
                "result": dados_estruturados["dados"]["interlocutor_name"],
                "duration_ms": round(name_duration, 2)
            })
        except Exception as e:
            update_user_state(id, message=f"Usuário: {message}")
            call_logger.log_error("INTENT_EXTRACTION_ERROR", 
                                str(e), 
                                {"stage": "interlocutor_name"})
            
            # Criar um dados_estruturados default
            dados_estruturados = {
                "mensagem": "Desculpe, não consegui entender seu nome. Poderia repetir?",
                "dados": partial_intent,
                "valid_for_action": False
            }

        if dados_estruturados["dados"]["interlocutor_name"] == "":
            ai_duration = (time.time() - total_start_time) * 1000
            call_logger.log_ai_processing_complete(dados_estruturados, ai_duration)
            return dados_estruturados

    state = get_user_state(id)
    history = "\n".join(state["history"])
    partial_intent = state["intent"]

    if state["intent"] and state["intent"]["apartment_number"] == "" or state["intent"]["resident_name"] == "":
        call_logger.log_event("INTENT_EXTRACTION_START", {
            "stage": "apartment_and_resident",
            "current_intent": str(partial_intent)
        })
        
        apt_start_time = time.time()
        task = conversation_extractor_resident_apartment_task(
            user_message=message,
            conversation_history=history,
            intent=partial_intent
        )
        crew = Crew(tasks=[task], verbose=True)
        result = str(crew.kickoff())
        apt_duration = (time.time() - apt_start_time) * 1000
        
        try:
            dados_estruturados = extract_intent_from_response(result)
            update_user_state(id, intent=dados_estruturados.get("dados"),
                              message=f"Usuário: {message}\nResposta LLM: {dados_estruturados.get('mensagem')}")
            
            call_logger.log_event("INTENT_EXTRACTION_COMPLETE", {
                "stage": "apartment_and_resident",
                "result": f"apt: {dados_estruturados['dados']['apartment_number']}, resident: {dados_estruturados['dados']['resident_name']}",
                "duration_ms": round(apt_duration, 2)
            })
        except Exception as e:
            update_user_state(id, message=f"Usuário: {message}")
            call_logger.log_error("INTENT_EXTRACTION_ERROR", 
                                str(e), 
                                {"stage": "apartment_and_resident"})
            
            # Criar um dados_estruturados default
            dados_estruturados = {
                "mensagem": "Desculpe, não consegui entender as informações do apartamento/morador. Poderia repetir?",
                "dados": partial_intent,
                "valid_for_action": False
            }

        if dados_estruturados["dados"]["apartment_number"] == "" or dados_estruturados["dados"]["resident_name"] == "":
            ai_duration = (time.time() - total_start_time) * 1000
            call_logger.log_ai_processing_complete(dados_estruturados, ai_duration)
            return dados_estruturados

        # É preciso retornar os dados para poder deixar a chamada em waiting enquanto processamos a intenção do usuário
        state = get_user_state(id)
        partial_intent = state["intent"]
        
        # Medição de tempo para validação fuzzy
        fuzzy_start_time = time.time()
        call_logger.log_event("FUZZY_VALIDATION_START", {"intent": str(partial_intent)})
        resultado = validar_intent_com_fuzzy(partial_intent)
        fuzzy_duration = (time.time() - fuzzy_start_time) * 1000
        
        call_logger.log_event("FUZZY_VALIDATION_COMPLETE", {
            "status": resultado["status"],
            "reason": resultado.get("reason", ""),
            "match_name": resultado.get("match_name", ""),
            "voip_number": resultado.get("voip_number", ""),
            "duration_ms": round(fuzzy_duration, 2)
        })

        if resultado["status"] == "inválido":
            # Zera apt/resident
            partial_intent["apartment_number"] = ""
            partial_intent["resident_name"] = ""

            invalid_response = {
                "mensagem": "Não encontrei esse apartamento/morador. Poderia repetir?",
                "dados": partial_intent,
                "valid_for_action": False
            }
            
            ai_duration = (time.time() - total_start_time) * 1000
            call_logger.log_ai_processing_complete(invalid_response, ai_duration)
            return invalid_response

        # Adicionar valid_for_action e outros metadados
        dados_estruturados["valid_for_action"] = True

    # Tempo total de processamento
    ai_duration = (time.time() - total_start_time) * 1000
    call_logger.log_ai_processing_complete(dados_estruturados, ai_duration)
    return dados_estruturados









    # # Cria a Task com histórico e dados parciais
    # task = create_conversation_coordinator_task(
    #     user_message=message,
    #     conversation_history=history,
    #     intent=partial_intent
    # )
    #
    # crew = Crew(tasks=[task], verbose=True)
    # result = str(crew.kickoff())
    #
    # # Tenta extrair novos dados (você pode usar OpenAI function calling ou Regex/JSON)
    # try:
    #     dados_estruturados = extract_intent_from_response(result)
    #     update_user_state(id, intent=dados_estruturados.get("dados"), message=f"Usuário: {message}\nResposta LLM: {dados_estruturados.get('mensagem')}")
    # except Exception:
    #     update_user_state(id, message=f"Usuário: {dados_estruturados.get('mensagem')}")
    #
    # return dados_estruturados


ai/main.py:
from ai.crew import process_user_message_with_coordinator



def process_message(content: str, id: str = "anon") -> dict:
    try:
        return process_user_message_with_coordinator(id=id, message=content)
            
    except Exception as e:
        print(f"Erro ao chamar CrewAI: {e}")
        return "Estou enfrentando alguns problemas técnicos. Por favor, tente novamente mais tarde."


ai/utils/__init__.py:


ai/utils/intent_extractor.py:
import json

from guardrails import Guard
from typing import Dict

from humanfriendly.terminal import message

from ai.models.intent import IntentData, IntentType, FullIntentResponse

# =======================
# 🛡️ RAILS SCHEMA (sem valid_for_action)
# =======================

INTENT_SCHEMA = """
<rail version="0.1">
<output>
  <object>
    <string name="mensagem" description="Mensagem a ser enviada ao usuário, clara e objetiva"/>
    <object name="dados">
      <string name="intent_type" format="enum" enum-values="visita,entrega,desconhecido"/>
      <string name="interlocutor_name" on-fail-soft="noop"/>
      <string name="apartment_number" on-fail-soft="noop"/>
      <string name="resident_name" on-fail-soft="noop"/>
    </object>
  </object>
</output>
</rail>
"""

guard = Guard.for_rail_string(INTENT_SCHEMA)

# =======================
# 🔍 EXTRACTOR
# =======================

def extract_intent_from_response(response: str) -> Dict:
    """
    Valida e extrai os dados de intenção usando Guardrails e Pydantic.
    Calcula valid_for_action com base nos campos preenchidos.
    """
    try:
        validated  = guard.parse(response)
        raw = validated.validated_output

        if not all(k in raw for k in ["mensagem", "dados"]):
            raise ValueError("Resposta fora do padrão esperado")

        if raw["dados"].get("intent_type") == "":
            raw["dados"]["intent_type"] = IntentType.DESCONHECIDO

        intent = IntentData(**raw["dados"])

        # Cálculo de completude
        campos_preenchidos = all([
            intent.intent_type != IntentType.DESCONHECIDO,
            intent.interlocutor_name.strip(),
            intent.apartment_number.strip(),
            intent.resident_name.strip()
        ])

        call_status = "USER_TURN"
        if campos_preenchidos:
            call_status = "WAITING"

        result = FullIntentResponse(
            mensagem=raw["mensagem"],
            dados=intent,
            valid_for_action=campos_preenchidos,
            set_call_status=call_status
        )

        return result.model_dump()
    except Exception as e:
        # Log do erro para diagnóstico (idealmente seria para um sistema de log)
        print(f"Erro ao extrair intenção: {str(e)}")
        
        # Tenta entender se a mensagem já é um JSON
        if isinstance(response, str) and response.strip().startswith('{') and response.strip().endswith('}'):
            try:
                # Tenta extrair JSON diretamente da resposta
                message_of_non_understanding = json.loads(response)
                if "mensagem" in message_of_non_understanding and "dados" in message_of_non_understanding:
                    # Garante que todos os campos necessários estejam presentes
                    if "intent_type" not in message_of_non_understanding["dados"]:
                        message_of_non_understanding["dados"]["intent_type"] = "desconhecido"
                    if "interlocutor_name" not in message_of_non_understanding["dados"]:
                        message_of_non_understanding["dados"]["interlocutor_name"] = ""
                    if "apartment_number" not in message_of_non_understanding["dados"]:
                        message_of_non_understanding["dados"]["apartment_number"] = ""
                    if "resident_name" not in message_of_non_understanding["dados"]:
                        message_of_non_understanding["dados"]["resident_name"] = ""
                    
                    message_of_non_understanding["valid_for_action"] = False
                    message_of_non_understanding["set_call_status"] = "USER_TURN"
                    return message_of_non_understanding
            except:
                # Se falhar na análise JSON, continua para a resposta padrão
                pass
                
        # Resposta padrão para casos de erro
        message_of_non_understanding = {
            "mensagem": "Desculpe, não consegui entender. Por favor, informe novamente o que deseja.",
            "dados": {
                "intent_type": "desconhecido",
                "interlocutor_name": "",
                "apartment_number": "",
                "resident_name": ""
            },
            "valid_for_action": False,
            "set_call_status": "USER_TURN"
        }
        
        return message_of_non_understanding


ai/models/intent.py:
from enum import Enum
from typing import Optional

from pydantic import BaseModel, Field

# =======================
# 🧠 MODELO DE INTENÇÃO
# =======================

class IntentType(str, Enum):
    VISITA = "visita"
    ENTREGA = "entrega"
    DESCONHECIDO = "desconhecido"

class IntentData(BaseModel):
    intent_type: IntentType = Field(..., description="Tipo de intenção identificada")
    interlocutor_name: str = Field("", description="Nome da pessoa no portão")
    apartment_number: str = Field("", description="Número do apartamento de destino")
    resident_name: str = Field("", description="Nome do morador/destinatário")

class FullIntentResponse(BaseModel):
    mensagem: str
    dados: IntentData
    valid_for_action: bool
    set_call_status: Optional[str] = "USER_TURN"


ai/models/__init__.py:


data/apartamentos.json:
[
  {
    "apartment_number": "101",
    "residents": ["Ana Beatriz Silva", "João Pedro Silva"],
    "voip_number": "sip:101@condominio.local"
  },
  {
    "apartment_number": "102",
    "residents": ["Carlos Oliveira"],
    "voip_number": "sip:102@condominio.local"
  },
  {
    "apartment_number": "201",
    "residents": ["Fernanda Souza", "Tiago Souza"],
    "voip_number": "sip:201@condominio.local"
  },
  {
    "apartment_number": "202",
    "residents": ["Mariana Costa"],
    "voip_number": "sip:202@condominio.local"
  },
  {
    "apartment_number": "301",
    "residents": ["Rodrigo Lima", "Letícia Lima"],
    "voip_number": "sip:301@condominio.local"
  },
  {
    "apartment_number": "302",
    "residents": ["Lucas Martins"],
    "voip_number": "sip:302@condominio.local"
  },
  {
    "apartment_number": "401",
    "residents": ["Paula Fernandes"],
    "voip_number": "sip:401@condominio.local"
  },
  {
    "apartment_number": "402",
    "residents": ["Eduardo Almeida", "Bruna Almeida"],
    "voip_number": "sip:402@condominio.local"
  },
  {
    "apartment_number": "501",
    "residents": ["Renata Oliveira", "Daner dos Reis"],
    "voip_number": "1003030"
  },
  {
    "apartment_number": "502",
    "residents": ["Vinícius Barros", "Marina Barros"],
    "voip_number": "sip:502@condominio.local"
  }
]


services/__init__.py:


services/amqp_service.py:

import pika
import json
import logging

def enviar_msg_autorizacao_morador(payload):
    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
    channel = connection.channel()

    channel.queue_declare(queue='fila_autorizacao')

    channel.basic_publish(
        exchange='',
        routing_key='fila_autorizacao',
        body=json.dumps(payload)
    )

    logging.info(f"Mensagem AMQP enviada: {payload}")
    connection.close()

